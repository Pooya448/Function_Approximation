{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 -  x^2 Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jdc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-06d59d86bb06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# importing needed modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjdc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jdc'"
     ]
    }
   ],
   "source": [
    "# importing needed modules\n",
    "import jdc as jdc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1d2770b6e8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generating training, cross-validation and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Generating training, cross-validation and test data\n",
    "\n",
    "X_train = np.random.uniform(low = -20, high = 20, size = 2000)\n",
    "Y_train = np.square(X_train)\n",
    "\n",
    "X_dev = np.random.uniform(low = -3, high = 3, size = 200)\n",
    "Y_dev = np.square(X_dev)\n",
    "\n",
    "X_test = np.random.uniform(low = -3, high = 3, size = 100)\n",
    "X_test.sort()\n",
    "Y_test = np.square(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-79d900a622fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(80, input_dim=1, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling Model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 200 samples\n",
      "Epoch 1/1500\n",
      "2000/2000 [==============================] - 0s 66us/step - loss: 32772.6482 - val_loss: 8.8376\n",
      "Epoch 2/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 30908.0528 - val_loss: 4.2937\n",
      "Epoch 3/1500\n",
      "2000/2000 [==============================] - 0s 13us/step - loss: 28307.2179 - val_loss: 1.9795\n",
      "Epoch 4/1500\n",
      "2000/2000 [==============================] - 0s 13us/step - loss: 24607.6955 - val_loss: 9.5921\n",
      "Epoch 5/1500\n",
      "2000/2000 [==============================] - 0s 13us/step - loss: 19593.8681 - val_loss: 46.2611\n",
      "Epoch 6/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 13643.0956 - val_loss: 143.1691\n",
      "Epoch 7/1500\n",
      "2000/2000 [==============================] - 0s 13us/step - loss: 7982.4273 - val_loss: 324.7325\n",
      "Epoch 8/1500\n",
      "2000/2000 [==============================] - 0s 13us/step - loss: 4151.2393 - val_loss: 557.1089\n",
      "Epoch 9/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 2568.5871 - val_loss: 720.4353\n",
      "Epoch 10/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 2290.4325 - val_loss: 760.5181\n",
      "Epoch 11/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 2262.4188 - val_loss: 736.1511\n",
      "Epoch 12/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 2235.9623 - val_loss: 697.7969\n",
      "Epoch 13/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 2209.9311 - val_loss: 663.9036\n",
      "Epoch 14/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 2182.8743 - val_loss: 634.1434\n",
      "Epoch 15/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 2157.1300 - val_loss: 603.3218\n",
      "Epoch 16/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 2130.6191 - val_loss: 571.5043\n",
      "Epoch 17/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 2103.7705 - val_loss: 545.1830\n",
      "Epoch 18/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 2076.4225 - val_loss: 521.7666\n",
      "Epoch 19/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 2048.7315 - val_loss: 494.6505\n",
      "Epoch 20/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 2021.9350 - val_loss: 464.3312\n",
      "Epoch 21/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1996.5673 - val_loss: 443.2928\n",
      "Epoch 22/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1966.3011 - val_loss: 415.1637\n",
      "Epoch 23/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1939.8575 - val_loss: 394.2589\n",
      "Epoch 24/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1913.1308 - val_loss: 371.0403\n",
      "Epoch 25/1500\n",
      "2000/2000 [==============================] - 0s 13us/step - loss: 1884.6163 - val_loss: 346.0445\n",
      "Epoch 26/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1855.4880 - val_loss: 324.4864\n",
      "Epoch 27/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1827.0023 - val_loss: 297.3268\n",
      "Epoch 28/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1794.6486 - val_loss: 277.5309\n",
      "Epoch 29/1500\n",
      "2000/2000 [==============================] - 0s 14us/step - loss: 1767.4496 - val_loss: 256.5150\n",
      "Epoch 30/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1735.9234 - val_loss: 239.3422\n",
      "Epoch 31/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1707.6118 - val_loss: 215.6250\n",
      "Epoch 32/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1674.9764 - val_loss: 198.9592\n",
      "Epoch 33/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1646.8726 - val_loss: 178.6800\n",
      "Epoch 34/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1609.5188 - val_loss: 160.4291\n",
      "Epoch 35/1500\n",
      "2000/2000 [==============================] - 0s 13us/step - loss: 1576.1063 - val_loss: 145.9011\n",
      "Epoch 36/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1542.2271 - val_loss: 130.1200\n",
      "Epoch 37/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1510.1429 - val_loss: 115.5866\n",
      "Epoch 38/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1473.6579 - val_loss: 101.3153\n",
      "Epoch 39/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1440.7092 - val_loss: 89.1716\n",
      "Epoch 40/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1406.1502 - val_loss: 78.3585\n",
      "Epoch 41/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1371.4884 - val_loss: 67.3402\n",
      "Epoch 42/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1337.0379 - val_loss: 57.5847\n",
      "Epoch 43/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1302.9346 - val_loss: 49.0408\n",
      "Epoch 44/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1269.1283 - val_loss: 41.5493\n",
      "Epoch 45/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1232.2263 - val_loss: 33.0746\n",
      "Epoch 46/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1197.9417 - val_loss: 28.5957\n",
      "Epoch 47/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1161.9069 - val_loss: 23.4887\n",
      "Epoch 48/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1123.9326 - val_loss: 18.9138\n",
      "Epoch 49/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1090.7519 - val_loss: 15.3187\n",
      "Epoch 50/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1054.1222 - val_loss: 12.3248\n",
      "Epoch 51/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1019.5070 - val_loss: 10.0007\n",
      "Epoch 52/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 983.8091 - val_loss: 8.4123\n",
      "Epoch 53/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 953.3276 - val_loss: 6.8463\n",
      "Epoch 54/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 914.2003 - val_loss: 5.6191\n",
      "Epoch 55/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 879.4409 - val_loss: 5.1720\n",
      "Epoch 56/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 843.2510 - val_loss: 4.7567\n",
      "Epoch 57/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 813.4682 - val_loss: 4.6769\n",
      "Epoch 58/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 781.6547 - val_loss: 5.1809\n",
      "Epoch 59/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 749.0784 - val_loss: 5.7090\n",
      "Epoch 60/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 719.7438 - val_loss: 6.2270\n",
      "Epoch 61/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 684.1601 - val_loss: 7.0408\n",
      "Epoch 62/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 653.9812 - val_loss: 7.9135\n",
      "Epoch 63/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 624.5496 - val_loss: 8.5281\n",
      "Epoch 64/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 593.7097 - val_loss: 9.2569\n",
      "Epoch 65/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 566.7548 - val_loss: 10.1267\n",
      "Epoch 66/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 536.3577 - val_loss: 11.2857\n",
      "Epoch 67/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 510.6465 - val_loss: 11.7112\n",
      "Epoch 68/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 485.4927 - val_loss: 12.3304\n",
      "Epoch 69/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 463.6399 - val_loss: 12.7230\n",
      "Epoch 70/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 439.8280 - val_loss: 13.0509\n",
      "Epoch 71/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 416.3777 - val_loss: 13.1707\n",
      "Epoch 72/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 395.4040 - val_loss: 13.2663\n",
      "Epoch 73/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 374.1239 - val_loss: 13.3843\n",
      "Epoch 74/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 356.2020 - val_loss: 13.4013\n",
      "Epoch 75/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 337.1945 - val_loss: 13.4013\n",
      "Epoch 76/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 320.1152 - val_loss: 13.4013\n",
      "Epoch 77/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 299.7611 - val_loss: 13.4013\n",
      "Epoch 78/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 285.4247 - val_loss: 13.4013\n",
      "Epoch 79/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 273.3690 - val_loss: 13.4013\n",
      "Epoch 80/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 261.4232 - val_loss: 13.4013\n",
      "Epoch 81/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 245.4380 - val_loss: 13.4013\n",
      "Epoch 82/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 230.8887 - val_loss: 13.4013\n",
      "Epoch 83/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 219.4488 - val_loss: 13.4013\n",
      "Epoch 84/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 208.8160 - val_loss: 13.4013\n",
      "Epoch 85/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 196.7322 - val_loss: 13.4013\n",
      "Epoch 86/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 187.4831 - val_loss: 13.4013\n",
      "Epoch 87/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 178.0997 - val_loss: 13.4013\n",
      "Epoch 88/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 169.7774 - val_loss: 13.4013\n",
      "Epoch 89/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 160.0735 - val_loss: 13.4013\n",
      "Epoch 90/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 153.6565 - val_loss: 13.4013\n",
      "Epoch 91/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 144.1448 - val_loss: 13.4013\n",
      "Epoch 92/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 140.0099 - val_loss: 13.4013\n",
      "Epoch 93/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 132.2072 - val_loss: 13.4013\n",
      "Epoch 94/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 124.9052 - val_loss: 13.4013\n",
      "Epoch 95/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 118.6981 - val_loss: 13.4013\n",
      "Epoch 96/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 112.9406 - val_loss: 13.4013\n",
      "Epoch 97/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 106.3427 - val_loss: 13.4013\n",
      "Epoch 98/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 99.4346 - val_loss: 13.4013\n",
      "Epoch 99/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 94.5680 - val_loss: 13.4013\n",
      "Epoch 100/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 90.1185 - val_loss: 13.4013\n",
      "Epoch 101/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 85.9785 - val_loss: 13.4013\n",
      "Epoch 102/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 83.3541 - val_loss: 13.4013\n",
      "Epoch 103/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 77.6000 - val_loss: 13.4013\n",
      "Epoch 104/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 74.7732 - val_loss: 13.4013\n",
      "Epoch 105/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 71.0068 - val_loss: 13.4013\n",
      "Epoch 106/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 68.5296 - val_loss: 13.4013\n",
      "Epoch 107/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 64.1608 - val_loss: 13.4013\n",
      "Epoch 108/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 61.7189 - val_loss: 13.4013\n",
      "Epoch 109/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 60.0196 - val_loss: 13.4013\n",
      "Epoch 110/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 55.7352 - val_loss: 13.4013\n",
      "Epoch 111/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 53.6618 - val_loss: 13.4013\n",
      "Epoch 112/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 52.1388 - val_loss: 13.4013\n",
      "Epoch 113/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 50.6164 - val_loss: 13.4013\n",
      "Epoch 114/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 47.1851 - val_loss: 13.4013\n",
      "Epoch 115/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 45.0380 - val_loss: 13.4013\n",
      "Epoch 116/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 43.7328 - val_loss: 13.4013\n",
      "Epoch 117/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 41.6100 - val_loss: 13.4013\n",
      "Epoch 118/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 41.1146 - val_loss: 13.4013\n",
      "Epoch 119/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 38.6464 - val_loss: 13.4013\n",
      "Epoch 120/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 37.2650 - val_loss: 13.4013\n",
      "Epoch 121/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 36.0035 - val_loss: 13.4013\n",
      "Epoch 122/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 34.8909 - val_loss: 13.4013\n",
      "Epoch 123/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 34.4278 - val_loss: 13.4013\n",
      "Epoch 124/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 32.7072 - val_loss: 13.4013\n",
      "Epoch 125/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 31.6892 - val_loss: 13.4013\n",
      "Epoch 126/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 30.4001 - val_loss: 13.4013\n",
      "Epoch 127/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 28.8272 - val_loss: 13.4013\n",
      "Epoch 128/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 28.1295 - val_loss: 13.4013\n",
      "Epoch 129/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 27.0419 - val_loss: 13.4013\n",
      "Epoch 130/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 26.6038 - val_loss: 13.4013\n",
      "Epoch 131/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 25.2678 - val_loss: 13.4013\n",
      "Epoch 132/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 24.5896 - val_loss: 13.4013\n",
      "Epoch 133/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 24.1105 - val_loss: 13.4013\n",
      "Epoch 134/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 23.1948 - val_loss: 13.4013\n",
      "Epoch 135/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 22.6890 - val_loss: 13.4013\n",
      "Epoch 136/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 21.6253 - val_loss: 13.4013\n",
      "Epoch 137/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 20.9829 - val_loss: 13.4013\n",
      "Epoch 138/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 20.2207 - val_loss: 13.4013\n",
      "Epoch 139/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 19.8091 - val_loss: 13.4013\n",
      "Epoch 140/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 19.0792 - val_loss: 13.4013\n",
      "Epoch 141/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 18.3994 - val_loss: 13.4013\n",
      "Epoch 142/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 17.8893 - val_loss: 13.4013\n",
      "Epoch 143/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 17.7029 - val_loss: 13.4013\n",
      "Epoch 144/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 17.3090 - val_loss: 13.4013\n",
      "Epoch 145/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 17.2515 - val_loss: 13.4013\n",
      "Epoch 146/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 17.3527 - val_loss: 13.4013\n",
      "Epoch 147/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 17.5943 - val_loss: 13.4013\n",
      "Epoch 148/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 15.5040 - val_loss: 13.4013\n",
      "Epoch 149/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 15.4420 - val_loss: 13.4013\n",
      "Epoch 150/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 15.1374 - val_loss: 13.3988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 14.6565 - val_loss: 13.3959\n",
      "Epoch 152/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 14.0501 - val_loss: 13.3747\n",
      "Epoch 153/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 13.9918 - val_loss: 13.3823\n",
      "Epoch 154/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 13.6467 - val_loss: 13.3643\n",
      "Epoch 155/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 12.9640 - val_loss: 13.3480\n",
      "Epoch 156/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 12.6718 - val_loss: 13.3263\n",
      "Epoch 157/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 12.3545 - val_loss: 13.3074\n",
      "Epoch 158/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 12.0570 - val_loss: 13.2921\n",
      "Epoch 159/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 11.5713 - val_loss: 13.2879\n",
      "Epoch 160/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 11.4530 - val_loss: 13.2600\n",
      "Epoch 161/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 11.2878 - val_loss: 13.2451\n",
      "Epoch 162/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 11.2131 - val_loss: 13.2210\n",
      "Epoch 163/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 10.6409 - val_loss: 13.2178\n",
      "Epoch 164/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 10.4518 - val_loss: 13.2023\n",
      "Epoch 165/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 10.1220 - val_loss: 13.1774\n",
      "Epoch 166/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 9.9802 - val_loss: 13.1642\n",
      "Epoch 167/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 9.8909 - val_loss: 13.1615\n",
      "Epoch 168/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 9.5429 - val_loss: 13.1353\n",
      "Epoch 169/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 9.2570 - val_loss: 13.1212\n",
      "Epoch 170/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 9.3483 - val_loss: 13.1025\n",
      "Epoch 171/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 9.0165 - val_loss: 13.0505\n",
      "Epoch 172/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 8.9700 - val_loss: 13.0694\n",
      "Epoch 173/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 8.9121 - val_loss: 13.0089\n",
      "Epoch 174/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 8.4464 - val_loss: 12.9974\n",
      "Epoch 175/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 8.2771 - val_loss: 12.9289\n",
      "Epoch 176/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 8.1863 - val_loss: 12.9120\n",
      "Epoch 177/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 8.0112 - val_loss: 12.8693\n",
      "Epoch 178/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 7.7501 - val_loss: 12.8122\n",
      "Epoch 179/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 7.7978 - val_loss: 12.8252\n",
      "Epoch 180/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 7.5079 - val_loss: 12.7184\n",
      "Epoch 181/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 7.3574 - val_loss: 12.6772\n",
      "Epoch 182/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 7.4892 - val_loss: 12.6422\n",
      "Epoch 183/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 7.1697 - val_loss: 12.5883\n",
      "Epoch 184/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 7.0285 - val_loss: 12.5585\n",
      "Epoch 185/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 6.8323 - val_loss: 12.5002\n",
      "Epoch 186/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 6.6771 - val_loss: 12.4329\n",
      "Epoch 187/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 6.8985 - val_loss: 12.3565\n",
      "Epoch 188/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 6.5674 - val_loss: 12.3657\n",
      "Epoch 189/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 6.5200 - val_loss: 12.2791\n",
      "Epoch 190/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 6.5668 - val_loss: 12.2959\n",
      "Epoch 191/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 6.2009 - val_loss: 12.2117\n",
      "Epoch 192/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 6.2286 - val_loss: 12.1787\n",
      "Epoch 193/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 6.1508 - val_loss: 12.0469\n",
      "Epoch 194/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.8747 - val_loss: 11.9880\n",
      "Epoch 195/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.9008 - val_loss: 11.9670\n",
      "Epoch 196/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.7794 - val_loss: 11.8488\n",
      "Epoch 197/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 5.7790 - val_loss: 11.8443\n",
      "Epoch 198/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.6631 - val_loss: 11.8392\n",
      "Epoch 199/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.5051 - val_loss: 11.7178\n",
      "Epoch 200/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.6015 - val_loss: 11.6368\n",
      "Epoch 201/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.5275 - val_loss: 11.6717\n",
      "Epoch 202/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.2904 - val_loss: 11.5671\n",
      "Epoch 203/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.2265 - val_loss: 11.5512\n",
      "Epoch 204/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.0763 - val_loss: 11.3905\n",
      "Epoch 205/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 5.0652 - val_loss: 11.3556\n",
      "Epoch 206/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 4.9602 - val_loss: 11.2534\n",
      "Epoch 207/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 4.9284 - val_loss: 11.1811\n",
      "Epoch 208/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.0850 - val_loss: 11.1289\n",
      "Epoch 209/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 5.0804 - val_loss: 10.9758\n",
      "Epoch 210/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 5.0090 - val_loss: 10.9591\n",
      "Epoch 211/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.7295 - val_loss: 10.9081\n",
      "Epoch 212/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.6832 - val_loss: 10.8692\n",
      "Epoch 213/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.7183 - val_loss: 10.7597\n",
      "Epoch 214/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.5270 - val_loss: 10.7134\n",
      "Epoch 215/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.5571 - val_loss: 10.6709\n",
      "Epoch 216/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.5266 - val_loss: 10.5677\n",
      "Epoch 217/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.6116 - val_loss: 10.5458\n",
      "Epoch 218/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 4.5402 - val_loss: 10.4637\n",
      "Epoch 219/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.2845 - val_loss: 10.3549\n",
      "Epoch 220/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.2578 - val_loss: 10.3093\n",
      "Epoch 221/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.1447 - val_loss: 10.2664\n",
      "Epoch 222/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.1190 - val_loss: 10.1921\n",
      "Epoch 223/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 4.0698 - val_loss: 10.0669\n",
      "Epoch 224/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.1603 - val_loss: 10.0137\n",
      "Epoch 225/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 4.0132 - val_loss: 9.9273\n",
      "Epoch 226/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 3.9640 - val_loss: 9.8670\n",
      "Epoch 227/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.8678 - val_loss: 9.7920\n",
      "Epoch 228/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.8267 - val_loss: 9.6990\n",
      "Epoch 229/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.7675 - val_loss: 9.6040\n",
      "Epoch 230/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 3.7347 - val_loss: 9.5543\n",
      "Epoch 231/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.7574 - val_loss: 9.4394\n",
      "Epoch 232/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.7442 - val_loss: 9.3326\n",
      "Epoch 233/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 3.7029 - val_loss: 9.2693\n",
      "Epoch 234/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 3.5560 - val_loss: 9.2526\n",
      "Epoch 235/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.5027 - val_loss: 9.2132\n",
      "Epoch 236/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.4640 - val_loss: 9.1559\n",
      "Epoch 237/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.5829 - val_loss: 9.0714\n",
      "Epoch 238/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.5019 - val_loss: 8.9811\n",
      "Epoch 239/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.4329 - val_loss: 8.9548\n",
      "Epoch 240/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.4114 - val_loss: 8.8874\n",
      "Epoch 241/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.2817 - val_loss: 8.7739\n",
      "Epoch 242/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.3499 - val_loss: 8.7483\n",
      "Epoch 243/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.2162 - val_loss: 8.6602\n",
      "Epoch 244/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 3.1217 - val_loss: 8.6508\n",
      "Epoch 245/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 3.2132 - val_loss: 8.5610\n",
      "Epoch 246/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 3.1542 - val_loss: 8.4243\n",
      "Epoch 247/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.1512 - val_loss: 8.3913\n",
      "Epoch 248/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.1504 - val_loss: 8.2776\n",
      "Epoch 249/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 2.9883 - val_loss: 8.2366\n",
      "Epoch 250/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.9458 - val_loss: 8.1126\n",
      "Epoch 251/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.9947 - val_loss: 8.1483\n",
      "Epoch 252/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.0585 - val_loss: 7.9636\n",
      "Epoch 253/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 3.0710 - val_loss: 7.8747\n",
      "Epoch 254/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.9408 - val_loss: 7.8567\n",
      "Epoch 255/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.8536 - val_loss: 7.7694\n",
      "Epoch 256/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.8888 - val_loss: 7.7345\n",
      "Epoch 257/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.7598 - val_loss: 7.6252\n",
      "Epoch 258/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.7589 - val_loss: 7.6639\n",
      "Epoch 259/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.7011 - val_loss: 7.4543\n",
      "Epoch 260/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.5595 - val_loss: 7.4121\n",
      "Epoch 261/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.5500 - val_loss: 7.3460\n",
      "Epoch 262/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 2.5297 - val_loss: 7.2845\n",
      "Epoch 263/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.4903 - val_loss: 7.2338\n",
      "Epoch 264/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.3826 - val_loss: 7.1121\n",
      "Epoch 265/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 2.4025 - val_loss: 7.1176\n",
      "Epoch 266/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.3797 - val_loss: 6.9699\n",
      "Epoch 267/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.3215 - val_loss: 6.9469\n",
      "Epoch 268/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.3881 - val_loss: 6.8722\n",
      "Epoch 269/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.2374 - val_loss: 6.8189\n",
      "Epoch 270/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.2531 - val_loss: 6.6778\n",
      "Epoch 271/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.1751 - val_loss: 6.6759\n",
      "Epoch 272/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.1842 - val_loss: 6.5896\n",
      "Epoch 273/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 2.1437 - val_loss: 6.5088\n",
      "Epoch 274/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.1357 - val_loss: 6.4853\n",
      "Epoch 275/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 2.2829 - val_loss: 6.3719\n",
      "Epoch 276/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 2.0796 - val_loss: 6.3743\n",
      "Epoch 277/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.9937 - val_loss: 6.2595\n",
      "Epoch 278/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.9602 - val_loss: 6.2751\n",
      "Epoch 279/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.9074 - val_loss: 6.1635\n",
      "Epoch 280/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.8850 - val_loss: 6.1350\n",
      "Epoch 281/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.8529 - val_loss: 6.0794\n",
      "Epoch 282/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.8820 - val_loss: 5.9975\n",
      "Epoch 283/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.8524 - val_loss: 5.9871\n",
      "Epoch 284/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 1.8111 - val_loss: 5.9214\n",
      "Epoch 285/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.8314 - val_loss: 5.8120\n",
      "Epoch 286/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.8836 - val_loss: 5.7965\n",
      "Epoch 287/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 2.0324 - val_loss: 5.6952\n",
      "Epoch 288/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 1.7194 - val_loss: 5.6404\n",
      "Epoch 289/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.8524 - val_loss: 5.5762\n",
      "Epoch 290/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 1.7636 - val_loss: 5.5222\n",
      "Epoch 291/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.8294 - val_loss: 5.5149\n",
      "Epoch 292/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.7063 - val_loss: 5.4118\n",
      "Epoch 293/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.5943 - val_loss: 5.3582\n",
      "Epoch 294/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.5768 - val_loss: 5.3821\n",
      "Epoch 295/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.5297 - val_loss: 5.2673\n",
      "Epoch 296/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.5559 - val_loss: 5.1992\n",
      "Epoch 297/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 1.5542 - val_loss: 5.1155\n",
      "Epoch 298/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 1.5414 - val_loss: 5.1114\n",
      "Epoch 299/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 1.4559 - val_loss: 5.0796\n",
      "Epoch 300/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.4183 - val_loss: 4.9963\n",
      "Epoch 301/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.4338 - val_loss: 4.9356\n",
      "Epoch 302/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.3992 - val_loss: 4.9374\n",
      "Epoch 303/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.4020 - val_loss: 4.9017\n",
      "Epoch 304/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.3702 - val_loss: 4.8028\n",
      "Epoch 305/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.3494 - val_loss: 4.8126\n",
      "Epoch 306/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.2921 - val_loss: 4.7273\n",
      "Epoch 307/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.2753 - val_loss: 4.6950\n",
      "Epoch 308/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.3330 - val_loss: 4.5964\n",
      "Epoch 309/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.3331 - val_loss: 4.5989\n",
      "Epoch 310/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.2264 - val_loss: 4.5485\n",
      "Epoch 311/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.3122 - val_loss: 4.5289\n",
      "Epoch 312/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1.2255 - val_loss: 4.4656\n",
      "Epoch 313/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1.1923 - val_loss: 4.3793\n",
      "Epoch 314/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.1701 - val_loss: 4.3292\n",
      "Epoch 315/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.1373 - val_loss: 4.3039\n",
      "Epoch 316/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 1.2039 - val_loss: 4.2660\n",
      "Epoch 317/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.1826 - val_loss: 4.2137\n",
      "Epoch 318/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.2555 - val_loss: 4.1397\n",
      "Epoch 319/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 1.1984 - val_loss: 4.1281\n",
      "Epoch 320/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.1000 - val_loss: 4.0976\n",
      "Epoch 321/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 1.1080 - val_loss: 4.0512\n",
      "Epoch 322/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.1841 - val_loss: 3.9526\n",
      "Epoch 323/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.0663 - val_loss: 3.9242\n",
      "Epoch 324/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.9936 - val_loss: 3.8309\n",
      "Epoch 325/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.0176 - val_loss: 3.8459\n",
      "Epoch 326/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.9918 - val_loss: 3.7842\n",
      "Epoch 327/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.9629 - val_loss: 3.7103\n",
      "Epoch 328/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.9400 - val_loss: 3.7071\n",
      "Epoch 329/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.9144 - val_loss: 3.6514\n",
      "Epoch 330/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.9342 - val_loss: 3.6198\n",
      "Epoch 331/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.9381 - val_loss: 3.5696\n",
      "Epoch 332/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.9784 - val_loss: 3.5728\n",
      "Epoch 333/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.9018 - val_loss: 3.4866\n",
      "Epoch 334/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.8936 - val_loss: 3.4306\n",
      "Epoch 335/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.8773 - val_loss: 3.4081\n",
      "Epoch 336/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.8881 - val_loss: 3.3586\n",
      "Epoch 337/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.8944 - val_loss: 3.3205\n",
      "Epoch 338/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.8582 - val_loss: 3.2748\n",
      "Epoch 339/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.8906 - val_loss: 3.2604\n",
      "Epoch 340/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.9069 - val_loss: 3.2008\n",
      "Epoch 341/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7713 - val_loss: 3.1744\n",
      "Epoch 342/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7682 - val_loss: 3.1468\n",
      "Epoch 343/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.7583 - val_loss: 3.0745\n",
      "Epoch 344/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7961 - val_loss: 3.0585\n",
      "Epoch 345/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7419 - val_loss: 3.0225\n",
      "Epoch 346/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7959 - val_loss: 2.9901\n",
      "Epoch 347/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7759 - val_loss: 2.9575\n",
      "Epoch 348/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7360 - val_loss: 2.9004\n",
      "Epoch 349/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7254 - val_loss: 2.8497\n",
      "Epoch 350/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7475 - val_loss: 2.8219\n",
      "Epoch 351/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7406 - val_loss: 2.7879\n",
      "Epoch 352/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6907 - val_loss: 2.7639\n",
      "Epoch 353/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6912 - val_loss: 2.7120\n",
      "Epoch 354/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6980 - val_loss: 2.6618\n",
      "Epoch 355/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6861 - val_loss: 2.6345\n",
      "Epoch 356/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6820 - val_loss: 2.6054\n",
      "Epoch 357/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6709 - val_loss: 2.5614\n",
      "Epoch 358/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6138 - val_loss: 2.5276\n",
      "Epoch 359/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.6182 - val_loss: 2.4990\n",
      "Epoch 360/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.6155 - val_loss: 2.4553\n",
      "Epoch 361/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6458 - val_loss: 2.4593\n",
      "Epoch 362/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5995 - val_loss: 2.3900\n",
      "Epoch 363/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5919 - val_loss: 2.3783\n",
      "Epoch 364/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.6032 - val_loss: 2.3500\n",
      "Epoch 365/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.6044 - val_loss: 2.3231\n",
      "Epoch 366/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.5682 - val_loss: 2.2962\n",
      "Epoch 367/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5756 - val_loss: 2.2808\n",
      "Epoch 368/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.5486 - val_loss: 2.2463\n",
      "Epoch 369/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5494 - val_loss: 2.2157\n",
      "Epoch 370/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5555 - val_loss: 2.2126\n",
      "Epoch 371/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.5556 - val_loss: 2.1639\n",
      "Epoch 372/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5278 - val_loss: 2.1559\n",
      "Epoch 373/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.5139 - val_loss: 2.1122\n",
      "Epoch 374/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5395 - val_loss: 2.0754\n",
      "Epoch 375/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5497 - val_loss: 2.0609\n",
      "Epoch 376/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5264 - val_loss: 2.0238\n",
      "Epoch 377/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5207 - val_loss: 2.0073\n",
      "Epoch 378/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5611 - val_loss: 1.9679\n",
      "Epoch 379/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5704 - val_loss: 1.9480\n",
      "Epoch 380/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5625 - val_loss: 1.9182\n",
      "Epoch 381/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4936 - val_loss: 1.9173\n",
      "Epoch 382/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.4882 - val_loss: 1.8995\n",
      "Epoch 383/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.5702 - val_loss: 1.8776\n",
      "Epoch 384/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5721 - val_loss: 1.8472\n",
      "Epoch 385/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.4733 - val_loss: 1.8212\n",
      "Epoch 386/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.4583 - val_loss: 1.8132\n",
      "Epoch 387/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.4711 - val_loss: 1.8058\n",
      "Epoch 388/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.4474 - val_loss: 1.7747\n",
      "Epoch 389/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.4555 - val_loss: 1.7609\n",
      "Epoch 390/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.4490 - val_loss: 1.7482\n",
      "Epoch 391/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4682 - val_loss: 1.7238\n",
      "Epoch 392/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5064 - val_loss: 1.6900\n",
      "Epoch 393/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4405 - val_loss: 1.6728\n",
      "Epoch 394/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4341 - val_loss: 1.6826\n",
      "Epoch 395/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4512 - val_loss: 1.6522\n",
      "Epoch 396/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4239 - val_loss: 1.6362\n",
      "Epoch 397/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4201 - val_loss: 1.6227\n",
      "Epoch 398/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4135 - val_loss: 1.6063\n",
      "Epoch 399/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4133 - val_loss: 1.5578\n",
      "Epoch 400/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4577 - val_loss: 1.5428\n",
      "Epoch 401/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4258 - val_loss: 1.5390\n",
      "Epoch 402/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4262 - val_loss: 1.5073\n",
      "Epoch 403/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4097 - val_loss: 1.5076\n",
      "Epoch 404/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5020 - val_loss: 1.4957\n",
      "Epoch 405/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.5212 - val_loss: 1.4822\n",
      "Epoch 406/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.4471 - val_loss: 1.4610\n",
      "Epoch 407/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4234 - val_loss: 1.4386\n",
      "Epoch 408/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4039 - val_loss: 1.4229\n",
      "Epoch 409/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.3845 - val_loss: 1.4045\n",
      "Epoch 410/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.5129 - val_loss: 1.3963\n",
      "Epoch 411/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4786 - val_loss: 1.3654\n",
      "Epoch 412/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.4131 - val_loss: 1.3592\n",
      "Epoch 413/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.3516 - val_loss: 1.3420\n",
      "Epoch 414/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3582 - val_loss: 1.3340\n",
      "Epoch 415/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3739 - val_loss: 1.3198\n",
      "Epoch 416/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.3969 - val_loss: 1.2966\n",
      "Epoch 417/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3562 - val_loss: 1.2834\n",
      "Epoch 418/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3954 - val_loss: 1.2801\n",
      "Epoch 419/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3650 - val_loss: 1.2661\n",
      "Epoch 420/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3273 - val_loss: 1.2530\n",
      "Epoch 421/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3691 - val_loss: 1.2339\n",
      "Epoch 422/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3946 - val_loss: 1.2142\n",
      "Epoch 423/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.3346 - val_loss: 1.2005\n",
      "Epoch 424/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.3497 - val_loss: 1.1892\n",
      "Epoch 425/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3740 - val_loss: 1.1803\n",
      "Epoch 426/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.3310 - val_loss: 1.1691\n",
      "Epoch 427/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3240 - val_loss: 1.1566\n",
      "Epoch 428/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3061 - val_loss: 1.1396\n",
      "Epoch 429/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.3335 - val_loss: 1.1226\n",
      "Epoch 430/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3400 - val_loss: 1.1119\n",
      "Epoch 431/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2979 - val_loss: 1.0917\n",
      "Epoch 432/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.3250 - val_loss: 1.0787\n",
      "Epoch 433/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3981 - val_loss: 1.0701\n",
      "Epoch 434/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3546 - val_loss: 1.0647\n",
      "Epoch 435/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3733 - val_loss: 1.0430\n",
      "Epoch 436/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3062 - val_loss: 1.0410\n",
      "Epoch 437/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.2780 - val_loss: 1.0346\n",
      "Epoch 438/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.2985 - val_loss: 1.0204\n",
      "Epoch 439/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2887 - val_loss: 1.0146\n",
      "Epoch 440/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2618 - val_loss: 0.9968\n",
      "Epoch 441/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.2723 - val_loss: 0.9893\n",
      "Epoch 442/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2563 - val_loss: 0.9808\n",
      "Epoch 443/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2843 - val_loss: 0.9717\n",
      "Epoch 444/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2680 - val_loss: 0.9611\n",
      "Epoch 445/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2516 - val_loss: 0.9560\n",
      "Epoch 446/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2639 - val_loss: 0.9399\n",
      "Epoch 447/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2986 - val_loss: 0.9346\n",
      "Epoch 448/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3084 - val_loss: 0.9320\n",
      "Epoch 449/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4294 - val_loss: 0.9164\n",
      "Epoch 450/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4685 - val_loss: 0.9110\n",
      "Epoch 451/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.2642 - val_loss: 0.9073\n",
      "Epoch 452/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2573 - val_loss: 0.8986\n",
      "Epoch 453/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.2434 - val_loss: 0.8919\n",
      "Epoch 454/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2293 - val_loss: 0.8824\n",
      "Epoch 455/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2268 - val_loss: 0.8726\n",
      "Epoch 456/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2490 - val_loss: 0.8692\n",
      "Epoch 457/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2384 - val_loss: 0.8621\n",
      "Epoch 458/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2238 - val_loss: 0.8535\n",
      "Epoch 459/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.2406 - val_loss: 0.8452\n",
      "Epoch 460/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.2547 - val_loss: 0.8435\n",
      "Epoch 461/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.3303 - val_loss: 0.8317\n",
      "Epoch 462/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.2523 - val_loss: 0.8287\n",
      "Epoch 463/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.2470 - val_loss: 0.8214\n",
      "Epoch 464/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.3432 - val_loss: 0.8211\n",
      "Epoch 465/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3068 - val_loss: 0.8033\n",
      "Epoch 466/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2101 - val_loss: 0.8013\n",
      "Epoch 467/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1995 - val_loss: 0.7960\n",
      "Epoch 468/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1939 - val_loss: 0.7886\n",
      "Epoch 469/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.2002 - val_loss: 0.7862\n",
      "Epoch 470/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3086 - val_loss: 0.7788\n",
      "Epoch 471/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2527 - val_loss: 0.7727\n",
      "Epoch 472/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2202 - val_loss: 0.7694\n",
      "Epoch 473/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1850 - val_loss: 0.7649\n",
      "Epoch 474/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1777 - val_loss: 0.7570\n",
      "Epoch 475/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1876 - val_loss: 0.7542\n",
      "Epoch 476/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2144 - val_loss: 0.7459\n",
      "Epoch 477/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1704 - val_loss: 0.7438\n",
      "Epoch 478/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1690 - val_loss: 0.7304\n",
      "Epoch 479/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1872 - val_loss: 0.7157\n",
      "Epoch 480/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3244 - val_loss: 0.7108\n",
      "Epoch 481/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2841 - val_loss: 0.6836\n",
      "Epoch 482/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.2035 - val_loss: 0.6520\n",
      "Epoch 483/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2904 - val_loss: 0.6215\n",
      "Epoch 484/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.2208 - val_loss: 0.5895\n",
      "Epoch 485/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1676 - val_loss: 0.5617\n",
      "Epoch 486/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1625 - val_loss: 0.5391\n",
      "Epoch 487/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1305 - val_loss: 0.5152\n",
      "Epoch 488/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1359 - val_loss: 0.4919\n",
      "Epoch 489/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1237 - val_loss: 0.4614\n",
      "Epoch 490/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1278 - val_loss: 0.4403\n",
      "Epoch 491/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1577 - val_loss: 0.4239\n",
      "Epoch 492/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1420 - val_loss: 0.3973\n",
      "Epoch 493/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1042 - val_loss: 0.3740\n",
      "Epoch 494/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1081 - val_loss: 0.3519\n",
      "Epoch 495/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1315 - val_loss: 0.3333\n",
      "Epoch 496/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1840 - val_loss: 0.3074\n",
      "Epoch 497/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1186 - val_loss: 0.2920\n",
      "Epoch 498/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0967 - val_loss: 0.2778\n",
      "Epoch 499/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1210 - val_loss: 0.2638\n",
      "Epoch 500/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0996 - val_loss: 0.2468\n",
      "Epoch 501/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0994 - val_loss: 0.2352\n",
      "Epoch 502/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0940 - val_loss: 0.2228\n",
      "Epoch 503/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0854 - val_loss: 0.2119\n",
      "Epoch 504/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0735 - val_loss: 0.2054\n",
      "Epoch 505/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0797 - val_loss: 0.1891\n",
      "Epoch 506/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1250 - val_loss: 0.1770\n",
      "Epoch 507/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1091 - val_loss: 0.1716\n",
      "Epoch 508/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0718 - val_loss: 0.1603\n",
      "Epoch 509/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0867 - val_loss: 0.1495\n",
      "Epoch 510/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 0.1105 - val_loss: 0.1408\n",
      "Epoch 511/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0845 - val_loss: 0.1309\n",
      "Epoch 512/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0681 - val_loss: 0.1244\n",
      "Epoch 513/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0563 - val_loss: 0.1154\n",
      "Epoch 514/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1217 - val_loss: 0.1126\n",
      "Epoch 515/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1971 - val_loss: 0.1061\n",
      "Epoch 516/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0777 - val_loss: 0.0964\n",
      "Epoch 517/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1372 - val_loss: 0.0922\n",
      "Epoch 518/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1277 - val_loss: 0.0888\n",
      "Epoch 519/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1116 - val_loss: 0.0870\n",
      "Epoch 520/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1746 - val_loss: 0.0844\n",
      "Epoch 521/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0981 - val_loss: 0.0809\n",
      "Epoch 522/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0577 - val_loss: 0.0779\n",
      "Epoch 523/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1048 - val_loss: 0.0761\n",
      "Epoch 524/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0872 - val_loss: 0.0759\n",
      "Epoch 525/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0522 - val_loss: 0.0731\n",
      "Epoch 526/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0648 - val_loss: 0.0706\n",
      "Epoch 527/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0639 - val_loss: 0.0685\n",
      "Epoch 528/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0907 - val_loss: 0.0692\n",
      "Epoch 529/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1207 - val_loss: 0.0671\n",
      "Epoch 530/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0650 - val_loss: 0.0662\n",
      "Epoch 531/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0438 - val_loss: 0.0652\n",
      "Epoch 532/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0500 - val_loss: 0.0639\n",
      "Epoch 533/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0835 - val_loss: 0.0629\n",
      "Epoch 534/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1501 - val_loss: 0.0616\n",
      "Epoch 535/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2678 - val_loss: 0.0612\n",
      "Epoch 536/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1292 - val_loss: 0.0609\n",
      "Epoch 537/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1185 - val_loss: 0.0602\n",
      "Epoch 538/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0919 - val_loss: 0.0591\n",
      "Epoch 539/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0525 - val_loss: 0.0582\n",
      "Epoch 540/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0523 - val_loss: 0.0582\n",
      "Epoch 541/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1041 - val_loss: 0.0569\n",
      "Epoch 542/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1006 - val_loss: 0.0572\n",
      "Epoch 543/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0895 - val_loss: 0.0564\n",
      "Epoch 544/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0726 - val_loss: 0.0552\n",
      "Epoch 545/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0416 - val_loss: 0.0540\n",
      "Epoch 546/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0604 - val_loss: 0.0538\n",
      "Epoch 547/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0494 - val_loss: 0.0527\n",
      "Epoch 548/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0424 - val_loss: 0.0518\n",
      "Epoch 549/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0365 - val_loss: 0.0497\n",
      "Epoch 550/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0462 - val_loss: 0.0495\n",
      "Epoch 551/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0496 - val_loss: 0.0473\n",
      "Epoch 552/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0577 - val_loss: 0.0458\n",
      "Epoch 553/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0376 - val_loss: 0.0438\n",
      "Epoch 554/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0475 - val_loss: 0.0429\n",
      "Epoch 555/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0568 - val_loss: 0.0415\n",
      "Epoch 556/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0480 - val_loss: 0.0390\n",
      "Epoch 557/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0841 - val_loss: 0.0378\n",
      "Epoch 558/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0902 - val_loss: 0.0353\n",
      "Epoch 559/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0401 - val_loss: 0.0335\n",
      "Epoch 560/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0380 - val_loss: 0.0317\n",
      "Epoch 561/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1056 - val_loss: 0.0300\n",
      "Epoch 562/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0446 - val_loss: 0.0292\n",
      "Epoch 563/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0348 - val_loss: 0.0270\n",
      "Epoch 564/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0612 - val_loss: 0.0257\n",
      "Epoch 565/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0634 - val_loss: 0.0237\n",
      "Epoch 566/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0457 - val_loss: 0.0228\n",
      "Epoch 567/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0863 - val_loss: 0.0215\n",
      "Epoch 568/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1870 - val_loss: 0.0212\n",
      "Epoch 569/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2220 - val_loss: 0.0207\n",
      "Epoch 570/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0591 - val_loss: 0.0179\n",
      "Epoch 571/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1215 - val_loss: 0.0170\n",
      "Epoch 572/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0368 - val_loss: 0.0160\n",
      "Epoch 573/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0392 - val_loss: 0.0146\n",
      "Epoch 574/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0467 - val_loss: 0.0137\n",
      "Epoch 575/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0895 - val_loss: 0.0138\n",
      "Epoch 576/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0460 - val_loss: 0.0122\n",
      "Epoch 577/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0541 - val_loss: 0.0117\n",
      "Epoch 578/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0341 - val_loss: 0.0108\n",
      "Epoch 579/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0273 - val_loss: 0.0102\n",
      "Epoch 580/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0339 - val_loss: 0.0098\n",
      "Epoch 581/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0835 - val_loss: 0.0098\n",
      "Epoch 582/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.1100 - val_loss: 0.0099\n",
      "Epoch 583/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1944 - val_loss: 0.0088\n",
      "Epoch 584/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1604 - val_loss: 0.0092\n",
      "Epoch 585/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2396 - val_loss: 0.0082\n",
      "Epoch 586/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1024 - val_loss: 0.0076\n",
      "Epoch 587/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0547 - val_loss: 0.0072\n",
      "Epoch 588/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0886 - val_loss: 0.0070\n",
      "Epoch 589/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1549 - val_loss: 0.0072\n",
      "Epoch 590/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1792 - val_loss: 0.0069\n",
      "Epoch 591/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1017 - val_loss: 0.0063\n",
      "Epoch 592/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0652 - val_loss: 0.0064\n",
      "Epoch 593/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1320 - val_loss: 0.0064\n",
      "Epoch 594/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2570 - val_loss: 0.0065\n",
      "Epoch 595/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1181 - val_loss: 0.0067\n",
      "Epoch 596/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0528 - val_loss: 0.0057\n",
      "Epoch 597/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0276 - val_loss: 0.0055\n",
      "Epoch 598/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0375 - val_loss: 0.0060\n",
      "Epoch 599/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0418 - val_loss: 0.0054\n",
      "Epoch 600/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0797 - val_loss: 0.0053\n",
      "Epoch 601/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0587 - val_loss: 0.0059\n",
      "Epoch 602/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0508 - val_loss: 0.0054\n",
      "Epoch 603/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0376 - val_loss: 0.0053\n",
      "Epoch 604/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0346 - val_loss: 0.0053\n",
      "Epoch 605/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0294 - val_loss: 0.0053\n",
      "Epoch 606/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0554 - val_loss: 0.0052\n",
      "Epoch 607/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0283 - val_loss: 0.0062\n",
      "Epoch 608/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0252 - val_loss: 0.0055\n",
      "Epoch 609/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0334 - val_loss: 0.0052\n",
      "Epoch 610/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0328 - val_loss: 0.0049\n",
      "Epoch 611/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0209 - val_loss: 0.0051\n",
      "Epoch 612/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0256 - val_loss: 0.0047\n",
      "Epoch 613/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2508 - val_loss: 0.0058\n",
      "Epoch 614/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1352 - val_loss: 0.0049\n",
      "Epoch 615/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0416 - val_loss: 0.0045\n",
      "Epoch 616/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0546 - val_loss: 0.0050\n",
      "Epoch 617/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0590 - val_loss: 0.0044\n",
      "Epoch 618/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0557 - val_loss: 0.0044\n",
      "Epoch 619/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0318 - val_loss: 0.0041\n",
      "Epoch 620/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0586 - val_loss: 0.0040\n",
      "Epoch 621/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0599 - val_loss: 0.0052\n",
      "Epoch 622/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0990 - val_loss: 0.0042\n",
      "Epoch 623/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0649 - val_loss: 0.0040\n",
      "Epoch 624/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1217 - val_loss: 0.0046\n",
      "Epoch 625/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0780 - val_loss: 0.0045\n",
      "Epoch 626/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0880 - val_loss: 0.0037\n",
      "Epoch 627/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.1026 - val_loss: 0.0039\n",
      "Epoch 628/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0634 - val_loss: 0.0043\n",
      "Epoch 629/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0351 - val_loss: 0.0037\n",
      "Epoch 630/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0264 - val_loss: 0.0039\n",
      "Epoch 631/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0249 - val_loss: 0.0036\n",
      "Epoch 632/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0330 - val_loss: 0.0040\n",
      "Epoch 633/1500\n",
      "2000/2000 [==============================] - 0s 12us/step - loss: 0.0691 - val_loss: 0.0036\n",
      "Epoch 634/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0635 - val_loss: 0.0035\n",
      "Epoch 635/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1428 - val_loss: 0.0034\n",
      "Epoch 636/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0863 - val_loss: 0.0034\n",
      "Epoch 637/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0429 - val_loss: 0.0042\n",
      "Epoch 638/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0509 - val_loss: 0.0038\n",
      "Epoch 639/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0321 - val_loss: 0.0036\n",
      "Epoch 640/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1549 - val_loss: 0.0038\n",
      "Epoch 641/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3206 - val_loss: 0.0052\n",
      "Epoch 642/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7696 - val_loss: 0.0034\n",
      "Epoch 643/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1697 - val_loss: 0.0039\n",
      "Epoch 644/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0448 - val_loss: 0.0032\n",
      "Epoch 645/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0410 - val_loss: 0.0032\n",
      "Epoch 646/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0426 - val_loss: 0.0030\n",
      "Epoch 647/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0496 - val_loss: 0.0029\n",
      "Epoch 648/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0464 - val_loss: 0.0037\n",
      "Epoch 649/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0322 - val_loss: 0.0029\n",
      "Epoch 650/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0320 - val_loss: 0.0035\n",
      "Epoch 651/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1028 - val_loss: 0.0029\n",
      "Epoch 652/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1342 - val_loss: 0.0032\n",
      "Epoch 653/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0880 - val_loss: 0.0028\n",
      "Epoch 654/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0286 - val_loss: 0.0027\n",
      "Epoch 655/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0428 - val_loss: 0.0028\n",
      "Epoch 656/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0503 - val_loss: 0.0028\n",
      "Epoch 657/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0449 - val_loss: 0.0028\n",
      "Epoch 658/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0333 - val_loss: 0.0028\n",
      "Epoch 659/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0221 - val_loss: 0.0032\n",
      "Epoch 660/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0243 - val_loss: 0.0026\n",
      "Epoch 661/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0264 - val_loss: 0.0025\n",
      "Epoch 662/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0235 - val_loss: 0.0028\n",
      "Epoch 663/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0296 - val_loss: 0.0026\n",
      "Epoch 664/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0311 - val_loss: 0.0027\n",
      "Epoch 665/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0303 - val_loss: 0.0027\n",
      "Epoch 666/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0316 - val_loss: 0.0027\n",
      "Epoch 667/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0425 - val_loss: 0.0024\n",
      "Epoch 668/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0417 - val_loss: 0.0025\n",
      "Epoch 669/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0659 - val_loss: 0.0028\n",
      "Epoch 670/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0305 - val_loss: 0.0026\n",
      "Epoch 671/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0231 - val_loss: 0.0025\n",
      "Epoch 672/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0298 - val_loss: 0.0025\n",
      "Epoch 673/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0734 - val_loss: 0.0025\n",
      "Epoch 674/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1113 - val_loss: 0.0033\n",
      "Epoch 675/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1673 - val_loss: 0.0025\n",
      "Epoch 676/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1691 - val_loss: 0.0027\n",
      "Epoch 677/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0424 - val_loss: 0.0023\n",
      "Epoch 678/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0900 - val_loss: 0.0024\n",
      "Epoch 679/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0520 - val_loss: 0.0026\n",
      "Epoch 680/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0396 - val_loss: 0.0026\n",
      "Epoch 681/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0479 - val_loss: 0.0025\n",
      "Epoch 682/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0874 - val_loss: 0.0024\n",
      "Epoch 683/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1354 - val_loss: 0.0023\n",
      "Epoch 684/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0466 - val_loss: 0.0025\n",
      "Epoch 685/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0348 - val_loss: 0.0021\n",
      "Epoch 686/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0634 - val_loss: 0.0024\n",
      "Epoch 687/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0280 - val_loss: 0.0023\n",
      "Epoch 688/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0204 - val_loss: 0.0023\n",
      "Epoch 689/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0207 - val_loss: 0.0021\n",
      "Epoch 690/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0293 - val_loss: 0.0023\n",
      "Epoch 691/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0398 - val_loss: 0.0022\n",
      "Epoch 692/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0339 - val_loss: 0.0023\n",
      "Epoch 693/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1129 - val_loss: 0.0026\n",
      "Epoch 694/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2801 - val_loss: 0.0041\n",
      "Epoch 695/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 1.2820 - val_loss: 0.0032\n",
      "Epoch 696/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.7043 - val_loss: 0.0061\n",
      "Epoch 697/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3053 - val_loss: 0.0023\n",
      "Epoch 698/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0635 - val_loss: 0.0028\n",
      "Epoch 699/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0287 - val_loss: 0.0022\n",
      "Epoch 700/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0022\n",
      "Epoch 701/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0185 - val_loss: 0.0023\n",
      "Epoch 702/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0270 - val_loss: 0.0024\n",
      "Epoch 703/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0246 - val_loss: 0.0020\n",
      "Epoch 704/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0484 - val_loss: 0.0018\n",
      "Epoch 705/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1114 - val_loss: 0.0021\n",
      "Epoch 706/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0741 - val_loss: 0.0022\n",
      "Epoch 707/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0497 - val_loss: 0.0021\n",
      "Epoch 708/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0336 - val_loss: 0.0023\n",
      "Epoch 709/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0306 - val_loss: 0.0025\n",
      "Epoch 710/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0228 - val_loss: 0.0019\n",
      "Epoch 711/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0193 - val_loss: 0.0018\n",
      "Epoch 712/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0219 - val_loss: 0.0017\n",
      "Epoch 713/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0330 - val_loss: 0.0017\n",
      "Epoch 714/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0413 - val_loss: 0.0017\n",
      "Epoch 715/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0377 - val_loss: 0.0020\n",
      "Epoch 716/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0255 - val_loss: 0.0019\n",
      "Epoch 717/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0217 - val_loss: 0.0018\n",
      "Epoch 718/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0220 - val_loss: 0.0016\n",
      "Epoch 719/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0286 - val_loss: 0.0017\n",
      "Epoch 720/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0486 - val_loss: 0.0016\n",
      "Epoch 721/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0258 - val_loss: 0.0017\n",
      "Epoch 722/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0492 - val_loss: 0.0014\n",
      "Epoch 723/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0442 - val_loss: 0.0018\n",
      "Epoch 724/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0384 - val_loss: 0.0017\n",
      "Epoch 725/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0215 - val_loss: 0.0017\n",
      "Epoch 726/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0654 - val_loss: 0.0015\n",
      "Epoch 727/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0525 - val_loss: 0.0022\n",
      "Epoch 728/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0250 - val_loss: 0.0019\n",
      "Epoch 729/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0161 - val_loss: 0.0014\n",
      "Epoch 730/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0178 - val_loss: 0.0014\n",
      "Epoch 731/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0490 - val_loss: 0.0014\n",
      "Epoch 732/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0305 - val_loss: 0.0017\n",
      "Epoch 733/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0248 - val_loss: 0.0013\n",
      "Epoch 734/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0399 - val_loss: 0.0017\n",
      "Epoch 735/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0567 - val_loss: 0.0018\n",
      "Epoch 736/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0409 - val_loss: 0.0013\n",
      "Epoch 737/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0374 - val_loss: 0.0017\n",
      "Epoch 738/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0356 - val_loss: 0.0013\n",
      "Epoch 739/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0546 - val_loss: 0.0011\n",
      "Epoch 740/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0602 - val_loss: 0.0014\n",
      "Epoch 741/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0562 - val_loss: 0.0011\n",
      "Epoch 742/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.2564 - val_loss: 0.0018\n",
      "Epoch 743/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.4716 - val_loss: 0.0018\n",
      "Epoch 744/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0915 - val_loss: 0.0014\n",
      "Epoch 745/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0923 - val_loss: 0.0022\n",
      "Epoch 746/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0356 - val_loss: 0.0012\n",
      "Epoch 747/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0435 - val_loss: 0.0012\n",
      "Epoch 748/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0449 - val_loss: 0.0017\n",
      "Epoch 749/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0283 - val_loss: 0.0013\n",
      "Epoch 750/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0211 - val_loss: 0.0011\n",
      "Epoch 751/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0281 - val_loss: 0.0014\n",
      "Epoch 752/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0222 - val_loss: 0.0013\n",
      "Epoch 753/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0258 - val_loss: 0.0012\n",
      "Epoch 754/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0235 - val_loss: 0.0010\n",
      "Epoch 755/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0288 - val_loss: 0.0011\n",
      "Epoch 756/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0274 - val_loss: 0.0011\n",
      "Epoch 757/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0207 - val_loss: 9.9395e-04\n",
      "Epoch 758/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0210 - val_loss: 0.0010\n",
      "Epoch 759/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0235 - val_loss: 0.0010\n",
      "Epoch 760/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0361 - val_loss: 0.0010\n",
      "Epoch 761/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0589 - val_loss: 0.0011\n",
      "Epoch 762/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1503 - val_loss: 0.0013\n",
      "Epoch 763/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0516 - val_loss: 0.0013\n",
      "Epoch 764/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0401 - val_loss: 0.0010\n",
      "Epoch 765/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0260 - val_loss: 9.3350e-04\n",
      "Epoch 766/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0293 - val_loss: 9.7301e-04\n",
      "Epoch 767/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0504 - val_loss: 9.9830e-04\n",
      "Epoch 768/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0264 - val_loss: 0.0010\n",
      "Epoch 769/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0211 - val_loss: 0.0011\n",
      "Epoch 770/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0182 - val_loss: 0.0010\n",
      "Epoch 771/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0265 - val_loss: 0.0012\n",
      "Epoch 772/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0420 - val_loss: 8.9058e-04\n",
      "Epoch 773/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0559 - val_loss: 0.0010\n",
      "Epoch 774/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0280 - val_loss: 0.0010\n",
      "Epoch 775/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0289 - val_loss: 0.0010\n",
      "Epoch 776/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0484 - val_loss: 8.7058e-04\n",
      "Epoch 777/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0423 - val_loss: 0.0013\n",
      "Epoch 778/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0460 - val_loss: 0.0012\n",
      "Epoch 779/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0336 - val_loss: 9.3413e-04\n",
      "Epoch 780/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0226 - val_loss: 9.1103e-04\n",
      "Epoch 781/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1123 - val_loss: 9.3565e-04\n",
      "Epoch 782/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0246 - val_loss: 0.0014\n",
      "Epoch 783/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0359 - val_loss: 8.7280e-04\n",
      "Epoch 784/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1269 - val_loss: 0.0014\n",
      "Epoch 785/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0865 - val_loss: 8.8515e-04\n",
      "Epoch 786/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0415 - val_loss: 0.0010\n",
      "Epoch 787/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0338 - val_loss: 9.9753e-04\n",
      "Epoch 788/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0281 - val_loss: 9.5715e-04\n",
      "Epoch 789/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0988 - val_loss: 0.0012\n",
      "Epoch 790/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0409 - val_loss: 0.0014\n",
      "Epoch 791/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0397 - val_loss: 8.9460e-04\n",
      "Epoch 792/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0652 - val_loss: 9.2278e-04\n",
      "Epoch 793/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1271 - val_loss: 0.0010\n",
      "Epoch 794/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3164 - val_loss: 0.0015\n",
      "Epoch 795/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1167 - val_loss: 0.0012\n",
      "Epoch 796/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0544 - val_loss: 0.0017\n",
      "Epoch 797/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0412 - val_loss: 0.0013\n",
      "Epoch 798/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0199 - val_loss: 9.4612e-04\n",
      "Epoch 799/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0178 - val_loss: 8.4863e-04\n",
      "Epoch 800/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0892 - val_loss: 9.5608e-04\n",
      "Epoch 801/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1555 - val_loss: 0.0013\n",
      "Epoch 802/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0351 - val_loss: 9.9493e-04\n",
      "Epoch 803/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0315 - val_loss: 0.0012\n",
      "Epoch 804/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0199 - val_loss: 8.8832e-04\n",
      "Epoch 805/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0170 - val_loss: 8.5279e-04\n",
      "Epoch 806/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0261 - val_loss: 0.0011\n",
      "Epoch 807/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2020 - val_loss: 0.0010\n",
      "Epoch 808/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0869 - val_loss: 0.0016\n",
      "Epoch 809/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0957 - val_loss: 0.0012\n",
      "Epoch 810/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1232 - val_loss: 0.0014\n",
      "Epoch 811/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0452 - val_loss: 0.0011\n",
      "Epoch 812/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0347 - val_loss: 8.9000e-04\n",
      "Epoch 813/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0586 - val_loss: 9.1006e-04\n",
      "Epoch 814/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0848 - val_loss: 8.0007e-04\n",
      "Epoch 815/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0257 - val_loss: 9.7882e-04\n",
      "Epoch 816/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0324 - val_loss: 9.9976e-04\n",
      "Epoch 817/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0269 - val_loss: 8.3600e-04\n",
      "Epoch 818/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0369 - val_loss: 8.0284e-04\n",
      "Epoch 819/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0270 - val_loss: 0.0010\n",
      "Epoch 820/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0329 - val_loss: 9.6901e-04\n",
      "Epoch 821/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0294 - val_loss: 0.0011\n",
      "Epoch 822/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0236 - val_loss: 9.8282e-04\n",
      "Epoch 823/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0359 - val_loss: 7.7039e-04\n",
      "Epoch 824/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0787 - val_loss: 0.0013\n",
      "Epoch 825/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0781 - val_loss: 0.0010\n",
      "Epoch 826/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0679 - val_loss: 7.6407e-04\n",
      "Epoch 827/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0327 - val_loss: 8.2451e-04\n",
      "Epoch 828/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0215 - val_loss: 8.2863e-04\n",
      "Epoch 829/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0242 - val_loss: 9.3347e-04\n",
      "Epoch 830/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0301 - val_loss: 7.6626e-04\n",
      "Epoch 831/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0355 - val_loss: 8.8078e-04\n",
      "Epoch 832/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0388 - val_loss: 0.0012\n",
      "Epoch 833/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0410 - val_loss: 0.0010\n",
      "Epoch 834/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0262 - val_loss: 7.3765e-04\n",
      "Epoch 835/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0267 - val_loss: 9.8210e-04\n",
      "Epoch 836/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0274 - val_loss: 7.1499e-04\n",
      "Epoch 837/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0367 - val_loss: 0.0012\n",
      "Epoch 838/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0325 - val_loss: 8.0211e-04\n",
      "Epoch 839/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0242 - val_loss: 9.6685e-04\n",
      "Epoch 840/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0400 - val_loss: 0.0010\n",
      "Epoch 841/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0529 - val_loss: 9.1533e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 842/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0706 - val_loss: 7.5925e-04\n",
      "Epoch 843/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1977 - val_loss: 7.3280e-04\n",
      "Epoch 844/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0845 - val_loss: 7.4364e-04\n",
      "Epoch 845/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1767 - val_loss: 8.8222e-04\n",
      "Epoch 846/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0989 - val_loss: 0.0017\n",
      "Epoch 847/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0243 - val_loss: 7.6532e-04\n",
      "Epoch 848/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0184 - val_loss: 7.7618e-04\n",
      "Epoch 849/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0272 - val_loss: 7.1806e-04\n",
      "Epoch 850/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0206 - val_loss: 7.7035e-04\n",
      "Epoch 851/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0211 - val_loss: 8.0928e-04\n",
      "Epoch 852/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0300 - val_loss: 7.9314e-04\n",
      "Epoch 853/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0555 - val_loss: 8.3025e-04\n",
      "Epoch 854/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0297 - val_loss: 6.7102e-04\n",
      "Epoch 855/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0360 - val_loss: 6.8154e-04\n",
      "Epoch 856/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0430 - val_loss: 9.5303e-04\n",
      "Epoch 857/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0335 - val_loss: 7.1409e-04\n",
      "Epoch 858/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 7.3180e-04\n",
      "Epoch 859/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0186 - val_loss: 8.4444e-04\n",
      "Epoch 860/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0332 - val_loss: 7.1665e-04\n",
      "Epoch 861/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0849 - val_loss: 0.0026\n",
      "Epoch 862/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0950 - val_loss: 6.8807e-04\n",
      "Epoch 863/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0874 - val_loss: 0.0010\n",
      "Epoch 864/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0885 - val_loss: 7.7128e-04\n",
      "Epoch 865/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1092 - val_loss: 8.2060e-04\n",
      "Epoch 866/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0336 - val_loss: 6.7409e-04\n",
      "Epoch 867/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0166 - val_loss: 6.7891e-04\n",
      "Epoch 868/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0271 - val_loss: 0.0011\n",
      "Epoch 869/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0294 - val_loss: 7.5850e-04\n",
      "Epoch 870/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1572 - val_loss: 0.0030\n",
      "Epoch 871/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2416 - val_loss: 0.0018\n",
      "Epoch 872/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2049 - val_loss: 0.0021\n",
      "Epoch 873/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1038 - val_loss: 0.0011\n",
      "Epoch 874/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1886 - val_loss: 7.4508e-04\n",
      "Epoch 875/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0521 - val_loss: 0.0011\n",
      "Epoch 876/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0191 - val_loss: 8.3029e-04\n",
      "Epoch 877/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0816 - val_loss: 7.4432e-04\n",
      "Epoch 878/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1362 - val_loss: 8.5935e-04\n",
      "Epoch 879/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0707 - val_loss: 0.0011\n",
      "Epoch 880/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0366 - val_loss: 8.5024e-04\n",
      "Epoch 881/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0312 - val_loss: 7.2643e-04\n",
      "Epoch 882/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0490 - val_loss: 7.3950e-04\n",
      "Epoch 883/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0465 - val_loss: 6.4373e-04\n",
      "Epoch 884/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0212 - val_loss: 8.3890e-04\n",
      "Epoch 885/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0288 - val_loss: 6.6394e-04\n",
      "Epoch 886/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0382 - val_loss: 0.0010\n",
      "Epoch 887/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0775 - val_loss: 8.6285e-04\n",
      "Epoch 888/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0436 - val_loss: 7.7630e-04\n",
      "Epoch 889/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0268 - val_loss: 8.2380e-04\n",
      "Epoch 890/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0231 - val_loss: 6.4252e-04\n",
      "Epoch 891/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0256 - val_loss: 9.4588e-04\n",
      "Epoch 892/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0376 - val_loss: 7.5368e-04\n",
      "Epoch 893/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0403 - val_loss: 6.6389e-04\n",
      "Epoch 894/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0417 - val_loss: 9.3385e-04\n",
      "Epoch 895/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0473 - val_loss: 8.6801e-04\n",
      "Epoch 896/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0210 - val_loss: 6.8348e-04\n",
      "Epoch 897/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0329 - val_loss: 6.9414e-04\n",
      "Epoch 898/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0521 - val_loss: 0.0013\n",
      "Epoch 899/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0791 - val_loss: 7.9113e-04\n",
      "Epoch 900/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0334 - val_loss: 6.3682e-04\n",
      "Epoch 901/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0297 - val_loss: 7.0713e-04\n",
      "Epoch 902/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0352 - val_loss: 6.3588e-04\n",
      "Epoch 903/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0354 - val_loss: 7.7546e-04\n",
      "Epoch 904/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0448 - val_loss: 7.6859e-04\n",
      "Epoch 905/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0235 - val_loss: 7.1497e-04\n",
      "Epoch 906/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1123 - val_loss: 0.0011\n",
      "Epoch 907/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1464 - val_loss: 6.3204e-04\n",
      "Epoch 908/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0722 - val_loss: 7.9103e-04\n",
      "Epoch 909/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0317 - val_loss: 7.5127e-04\n",
      "Epoch 910/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1106 - val_loss: 8.1325e-04\n",
      "Epoch 911/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0770 - val_loss: 9.4613e-04\n",
      "Epoch 912/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1187 - val_loss: 9.7759e-04\n",
      "Epoch 913/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1917 - val_loss: 9.3452e-04\n",
      "Epoch 914/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1268 - val_loss: 0.0014\n",
      "Epoch 915/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0216 - val_loss: 7.2350e-04\n",
      "Epoch 916/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0205 - val_loss: 6.3375e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 917/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0146 - val_loss: 6.4629e-04\n",
      "Epoch 918/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0332 - val_loss: 6.2547e-04\n",
      "Epoch 919/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0800 - val_loss: 0.0014\n",
      "Epoch 920/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0839 - val_loss: 6.2920e-04\n",
      "Epoch 921/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.2971 - val_loss: 0.0019\n",
      "Epoch 922/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1680 - val_loss: 0.0028\n",
      "Epoch 923/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1255 - val_loss: 7.8243e-04\n",
      "Epoch 924/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1176 - val_loss: 0.0012\n",
      "Epoch 925/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1517 - val_loss: 0.0011\n",
      "Epoch 926/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0644 - val_loss: 7.0713e-04\n",
      "Epoch 927/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0732 - val_loss: 6.7070e-04\n",
      "Epoch 928/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0383 - val_loss: 6.6809e-04\n",
      "Epoch 929/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0241 - val_loss: 6.3102e-04\n",
      "Epoch 930/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0183 - val_loss: 8.0717e-04\n",
      "Epoch 931/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0365 - val_loss: 7.0266e-04\n",
      "Epoch 932/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0324 - val_loss: 7.5965e-04\n",
      "Epoch 933/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0200 - val_loss: 7.1960e-04\n",
      "Epoch 934/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0277 - val_loss: 6.5173e-04\n",
      "Epoch 935/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0252 - val_loss: 5.8381e-04\n",
      "Epoch 936/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0184 - val_loss: 6.1987e-04\n",
      "Epoch 937/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0143 - val_loss: 6.2433e-04\n",
      "Epoch 938/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0175 - val_loss: 6.9816e-04\n",
      "Epoch 939/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0425 - val_loss: 6.1273e-04\n",
      "Epoch 940/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0586 - val_loss: 6.3542e-04\n",
      "Epoch 941/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0290 - val_loss: 0.0012\n",
      "Epoch 942/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0331 - val_loss: 9.8942e-04\n",
      "Epoch 943/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0553 - val_loss: 0.0011\n",
      "Epoch 944/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0476 - val_loss: 0.0010\n",
      "Epoch 945/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0501 - val_loss: 6.4507e-04\n",
      "Epoch 946/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0229 - val_loss: 6.1462e-04\n",
      "Epoch 947/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0178 - val_loss: 5.9606e-04\n",
      "Epoch 948/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0183 - val_loss: 6.2159e-04\n",
      "Epoch 949/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0335 - val_loss: 7.1643e-04\n",
      "Epoch 950/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0461 - val_loss: 5.6801e-04\n",
      "Epoch 951/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0786 - val_loss: 0.0010\n",
      "Epoch 952/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0502 - val_loss: 8.8653e-04\n",
      "Epoch 953/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0979 - val_loss: 7.8580e-04\n",
      "Epoch 954/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0602 - val_loss: 6.4788e-04\n",
      "Epoch 955/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0250 - val_loss: 7.0676e-04\n",
      "Epoch 956/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0221 - val_loss: 5.9242e-04\n",
      "Epoch 957/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0952 - val_loss: 6.3200e-04\n",
      "Epoch 958/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0887 - val_loss: 9.1848e-04\n",
      "Epoch 959/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0676 - val_loss: 6.4217e-04\n",
      "Epoch 960/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0342 - val_loss: 0.0014\n",
      "Epoch 961/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0246 - val_loss: 5.6126e-04\n",
      "Epoch 962/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0732 - val_loss: 6.1196e-04\n",
      "Epoch 963/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1038 - val_loss: 6.5579e-04\n",
      "Epoch 964/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0271 - val_loss: 6.1323e-04\n",
      "Epoch 965/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0841 - val_loss: 0.0020\n",
      "Epoch 966/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1537 - val_loss: 9.7145e-04\n",
      "Epoch 967/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0294 - val_loss: 8.9129e-04\n",
      "Epoch 968/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0742 - val_loss: 8.8812e-04\n",
      "Epoch 969/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0508 - val_loss: 9.3699e-04\n",
      "Epoch 970/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0258 - val_loss: 6.7300e-04\n",
      "Epoch 971/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0975 - val_loss: 8.0155e-04\n",
      "Epoch 972/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1133 - val_loss: 7.9262e-04\n",
      "Epoch 973/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0872 - val_loss: 5.7125e-04\n",
      "Epoch 974/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0671 - val_loss: 0.0012\n",
      "Epoch 975/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0385 - val_loss: 0.0010\n",
      "Epoch 976/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0216 - val_loss: 6.1083e-04\n",
      "Epoch 977/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0373 - val_loss: 5.8920e-04\n",
      "Epoch 978/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0243 - val_loss: 5.8726e-04\n",
      "Epoch 979/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0339 - val_loss: 0.0010\n",
      "Epoch 980/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0456 - val_loss: 7.6162e-04\n",
      "Epoch 981/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0754 - val_loss: 9.5740e-04\n",
      "Epoch 982/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0489 - val_loss: 0.0016\n",
      "Epoch 983/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0283 - val_loss: 5.9312e-04\n",
      "Epoch 984/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0718 - val_loss: 6.2197e-04\n",
      "Epoch 985/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1087 - val_loss: 6.0562e-04\n",
      "Epoch 986/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1523 - val_loss: 7.4719e-04\n",
      "Epoch 987/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2445 - val_loss: 0.0012\n",
      "Epoch 988/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1213 - val_loss: 6.4570e-04\n",
      "Epoch 989/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0642 - val_loss: 0.0010\n",
      "Epoch 990/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0792 - val_loss: 0.0014\n",
      "Epoch 991/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0319 - val_loss: 8.8194e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 992/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0296 - val_loss: 5.6791e-04\n",
      "Epoch 993/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0471 - val_loss: 6.6118e-04\n",
      "Epoch 994/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2396 - val_loss: 9.0670e-04\n",
      "Epoch 995/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2009 - val_loss: 5.8205e-04\n",
      "Epoch 996/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2795 - val_loss: 8.0799e-04\n",
      "Epoch 997/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1093 - val_loss: 0.0011\n",
      "Epoch 998/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0676 - val_loss: 8.4679e-04\n",
      "Epoch 999/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0239 - val_loss: 5.5441e-04\n",
      "Epoch 1000/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0176 - val_loss: 5.3745e-04\n",
      "Epoch 1001/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0174 - val_loss: 6.3084e-04\n",
      "Epoch 1002/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0677 - val_loss: 0.0013\n",
      "Epoch 1003/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1072 - val_loss: 5.7101e-04\n",
      "Epoch 1004/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0625 - val_loss: 9.5334e-04\n",
      "Epoch 1005/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0396 - val_loss: 6.9013e-04\n",
      "Epoch 1006/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0261 - val_loss: 6.1943e-04\n",
      "Epoch 1007/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0215 - val_loss: 5.6940e-04\n",
      "Epoch 1008/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0218 - val_loss: 5.5785e-04\n",
      "Epoch 1009/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0245 - val_loss: 6.3052e-04\n",
      "Epoch 1010/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0164 - val_loss: 5.7351e-04\n",
      "Epoch 1011/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0151 - val_loss: 5.3936e-04\n",
      "Epoch 1012/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0273 - val_loss: 5.7262e-04\n",
      "Epoch 1013/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0371 - val_loss: 7.5996e-04\n",
      "Epoch 1014/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0630 - val_loss: 0.0011\n",
      "Epoch 1015/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0751 - val_loss: 7.3522e-04\n",
      "Epoch 1016/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0419 - val_loss: 5.8285e-04\n",
      "Epoch 1017/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0214 - val_loss: 5.4272e-04\n",
      "Epoch 1018/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0176 - val_loss: 9.2444e-04\n",
      "Epoch 1019/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0310 - val_loss: 7.6752e-04\n",
      "Epoch 1020/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0214 - val_loss: 5.6525e-04\n",
      "Epoch 1021/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0267 - val_loss: 7.3041e-04\n",
      "Epoch 1022/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0272 - val_loss: 5.0829e-04\n",
      "Epoch 1023/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0201 - val_loss: 5.8702e-04\n",
      "Epoch 1024/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0328 - val_loss: 6.0871e-04\n",
      "Epoch 1025/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0371 - val_loss: 7.3821e-04\n",
      "Epoch 1026/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0213 - val_loss: 6.3457e-04\n",
      "Epoch 1027/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0233 - val_loss: 5.0592e-04\n",
      "Epoch 1028/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0246 - val_loss: 8.3324e-04\n",
      "Epoch 1029/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0364 - val_loss: 4.9769e-04\n",
      "Epoch 1030/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0753 - val_loss: 0.0013\n",
      "Epoch 1031/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0600 - val_loss: 7.8707e-04\n",
      "Epoch 1032/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0550 - val_loss: 5.9024e-04\n",
      "Epoch 1033/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0525 - val_loss: 5.0609e-04\n",
      "Epoch 1034/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0664 - val_loss: 6.4570e-04\n",
      "Epoch 1035/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0634 - val_loss: 6.3103e-04\n",
      "Epoch 1036/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0494 - val_loss: 0.0012\n",
      "Epoch 1037/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1707 - val_loss: 8.5320e-04\n",
      "Epoch 1038/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1743 - val_loss: 9.3995e-04\n",
      "Epoch 1039/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0597 - val_loss: 0.0014\n",
      "Epoch 1040/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0985 - val_loss: 9.2844e-04\n",
      "Epoch 1041/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2543 - val_loss: 0.0017\n",
      "Epoch 1042/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0621 - val_loss: 9.3508e-04\n",
      "Epoch 1043/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0216 - val_loss: 5.5938e-04\n",
      "Epoch 1044/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0165 - val_loss: 6.0613e-04\n",
      "Epoch 1045/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0148 - val_loss: 5.5675e-04\n",
      "Epoch 1046/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0582 - val_loss: 0.0010\n",
      "Epoch 1047/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0542 - val_loss: 5.1470e-04\n",
      "Epoch 1048/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0310 - val_loss: 5.5388e-04\n",
      "Epoch 1049/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0250 - val_loss: 5.6385e-04\n",
      "Epoch 1050/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0198 - val_loss: 5.4228e-04\n",
      "Epoch 1051/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0549 - val_loss: 7.5089e-04\n",
      "Epoch 1052/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0181 - val_loss: 6.7608e-04\n",
      "Epoch 1053/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0192 - val_loss: 6.3400e-04\n",
      "Epoch 1054/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0338 - val_loss: 6.3873e-04\n",
      "Epoch 1055/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0586 - val_loss: 5.0758e-04\n",
      "Epoch 1056/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0694 - val_loss: 5.5425e-04\n",
      "Epoch 1057/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3140 - val_loss: 0.0021\n",
      "Epoch 1058/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2241 - val_loss: 9.6025e-04\n",
      "Epoch 1059/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0682 - val_loss: 8.0880e-04\n",
      "Epoch 1060/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0233 - val_loss: 5.5507e-04\n",
      "Epoch 1061/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0252 - val_loss: 5.6403e-04\n",
      "Epoch 1062/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0169 - val_loss: 6.6226e-04\n",
      "Epoch 1063/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0195 - val_loss: 5.7206e-04\n",
      "Epoch 1064/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0170 - val_loss: 6.3116e-04\n",
      "Epoch 1065/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0162 - val_loss: 5.3509e-04\n",
      "Epoch 1066/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0167 - val_loss: 6.7196e-04\n",
      "Epoch 1067/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0173 - val_loss: 5.0650e-04\n",
      "Epoch 1068/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0197 - val_loss: 5.6467e-04\n",
      "Epoch 1069/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0722 - val_loss: 5.5998e-04\n",
      "Epoch 1070/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0550 - val_loss: 0.0011\n",
      "Epoch 1071/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0476 - val_loss: 6.1460e-04\n",
      "Epoch 1072/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0325 - val_loss: 6.3238e-04\n",
      "Epoch 1073/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0370 - val_loss: 9.6130e-04\n",
      "Epoch 1074/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1272 - val_loss: 0.0022\n",
      "Epoch 1075/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1504 - val_loss: 5.8628e-04\n",
      "Epoch 1076/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0223 - val_loss: 4.6629e-04\n",
      "Epoch 1077/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0200 - val_loss: 5.5954e-04\n",
      "Epoch 1078/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0381 - val_loss: 8.2064e-04\n",
      "Epoch 1079/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0382 - val_loss: 5.4452e-04\n",
      "Epoch 1080/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0217 - val_loss: 4.8395e-04\n",
      "Epoch 1081/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0259 - val_loss: 4.8899e-04\n",
      "Epoch 1082/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0385 - val_loss: 5.1034e-04\n",
      "Epoch 1083/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0365 - val_loss: 4.9304e-04\n",
      "Epoch 1084/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0537 - val_loss: 5.6753e-04\n",
      "Epoch 1085/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0396 - val_loss: 4.9232e-04\n",
      "Epoch 1086/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0407 - val_loss: 5.0805e-04\n",
      "Epoch 1087/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0319 - val_loss: 8.5238e-04\n",
      "Epoch 1088/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0234 - val_loss: 5.5388e-04\n",
      "Epoch 1089/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0308 - val_loss: 4.3126e-04\n",
      "Epoch 1090/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0251 - val_loss: 5.4357e-04\n",
      "Epoch 1091/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0288 - val_loss: 4.9071e-04\n",
      "Epoch 1092/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0235 - val_loss: 4.3895e-04\n",
      "Epoch 1093/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0254 - val_loss: 4.2126e-04\n",
      "Epoch 1094/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0165 - val_loss: 4.3467e-04\n",
      "Epoch 1095/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0551 - val_loss: 4.6981e-04\n",
      "Epoch 1096/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0558 - val_loss: 6.6835e-04\n",
      "Epoch 1097/1500\n",
      "2000/2000 [==============================] - 0s 13us/step - loss: 0.0818 - val_loss: 6.0885e-04\n",
      "Epoch 1098/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0240 - val_loss: 5.6652e-04\n",
      "Epoch 1099/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0182 - val_loss: 4.5418e-04\n",
      "Epoch 1100/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0334 - val_loss: 4.7409e-04\n",
      "Epoch 1101/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0983 - val_loss: 0.0012\n",
      "Epoch 1102/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1876 - val_loss: 7.1719e-04\n",
      "Epoch 1103/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0650 - val_loss: 4.1489e-04\n",
      "Epoch 1104/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0185 - val_loss: 5.2111e-04\n",
      "Epoch 1105/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0228 - val_loss: 5.8712e-04\n",
      "Epoch 1106/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0837 - val_loss: 6.2202e-04\n",
      "Epoch 1107/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1083 - val_loss: 4.6609e-04\n",
      "Epoch 1108/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0813 - val_loss: 4.4487e-04\n",
      "Epoch 1109/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1260 - val_loss: 0.0028\n",
      "Epoch 1110/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0375 - val_loss: 0.0012\n",
      "Epoch 1111/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0217 - val_loss: 7.4164e-04\n",
      "Epoch 1112/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0216 - val_loss: 4.7108e-04\n",
      "Epoch 1113/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0677 - val_loss: 5.3846e-04\n",
      "Epoch 1114/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0454 - val_loss: 7.7052e-04\n",
      "Epoch 1115/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0685 - val_loss: 4.4448e-04\n",
      "Epoch 1116/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0183 - val_loss: 4.6265e-04\n",
      "Epoch 1117/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0225 - val_loss: 4.5919e-04\n",
      "Epoch 1118/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0250 - val_loss: 4.1965e-04\n",
      "Epoch 1119/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0284 - val_loss: 5.6484e-04\n",
      "Epoch 1120/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0366 - val_loss: 5.9440e-04\n",
      "Epoch 1121/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0210 - val_loss: 3.9983e-04\n",
      "Epoch 1122/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1197 - val_loss: 5.9781e-04\n",
      "Epoch 1123/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0984 - val_loss: 6.0834e-04\n",
      "Epoch 1124/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0360 - val_loss: 7.7926e-04\n",
      "Epoch 1125/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0559 - val_loss: 5.0939e-04\n",
      "Epoch 1126/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0295 - val_loss: 5.9033e-04\n",
      "Epoch 1127/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0191 - val_loss: 4.0723e-04\n",
      "Epoch 1128/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0467 - val_loss: 8.2766e-04\n",
      "Epoch 1129/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3811 - val_loss: 0.0042\n",
      "Epoch 1130/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.6021 - val_loss: 0.0018\n",
      "Epoch 1131/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2778 - val_loss: 0.0015\n",
      "Epoch 1132/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1066 - val_loss: 0.0016\n",
      "Epoch 1133/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0802 - val_loss: 5.1899e-04\n",
      "Epoch 1134/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0348 - val_loss: 4.1236e-04\n",
      "Epoch 1135/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0472 - val_loss: 4.3326e-04\n",
      "Epoch 1136/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0303 - val_loss: 3.9215e-04\n",
      "Epoch 1137/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0591 - val_loss: 4.6867e-04\n",
      "Epoch 1138/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0397 - val_loss: 4.6407e-04\n",
      "Epoch 1139/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0204 - val_loss: 3.9982e-04\n",
      "Epoch 1140/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0218 - val_loss: 3.6522e-04\n",
      "Epoch 1141/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0283 - val_loss: 3.9661e-04\n",
      "Epoch 1142/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0354 - val_loss: 4.2082e-04\n",
      "Epoch 1143/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0601 - val_loss: 4.5169e-04\n",
      "Epoch 1144/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0289 - val_loss: 3.9554e-04\n",
      "Epoch 1145/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0274 - val_loss: 3.5000e-04\n",
      "Epoch 1146/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0240 - val_loss: 3.5038e-04\n",
      "Epoch 1147/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0152 - val_loss: 3.4533e-04\n",
      "Epoch 1148/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0379 - val_loss: 4.0617e-04\n",
      "Epoch 1149/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0349 - val_loss: 4.1677e-04\n",
      "Epoch 1150/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0171 - val_loss: 3.3349e-04\n",
      "Epoch 1151/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0191 - val_loss: 3.6480e-04\n",
      "Epoch 1152/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0326 - val_loss: 4.4903e-04\n",
      "Epoch 1153/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0720 - val_loss: 3.7766e-04\n",
      "Epoch 1154/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0335 - val_loss: 8.6271e-04\n",
      "Epoch 1155/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0812 - val_loss: 8.7099e-04\n",
      "Epoch 1156/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0282 - val_loss: 3.2538e-04\n",
      "Epoch 1157/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0171 - val_loss: 3.4691e-04\n",
      "Epoch 1158/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1120 - val_loss: 5.1445e-04\n",
      "Epoch 1159/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2006 - val_loss: 8.6474e-04\n",
      "Epoch 1160/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1587 - val_loss: 0.0012\n",
      "Epoch 1161/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0446 - val_loss: 5.1246e-04\n",
      "Epoch 1162/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0271 - val_loss: 3.3741e-04\n",
      "Epoch 1163/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0223 - val_loss: 4.3320e-04\n",
      "Epoch 1164/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0246 - val_loss: 3.2752e-04\n",
      "Epoch 1165/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0233 - val_loss: 7.1264e-04\n",
      "Epoch 1166/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0324 - val_loss: 3.5139e-04\n",
      "Epoch 1167/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0204 - val_loss: 3.0844e-04\n",
      "Epoch 1168/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0315 - val_loss: 5.1287e-04\n",
      "Epoch 1169/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0372 - val_loss: 3.1003e-04\n",
      "Epoch 1170/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0459 - val_loss: 3.6202e-04\n",
      "Epoch 1171/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0437 - val_loss: 4.9799e-04\n",
      "Epoch 1172/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0486 - val_loss: 3.7350e-04\n",
      "Epoch 1173/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0282 - val_loss: 3.1171e-04\n",
      "Epoch 1174/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0318 - val_loss: 3.1315e-04\n",
      "Epoch 1175/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0278 - val_loss: 3.9903e-04\n",
      "Epoch 1176/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0219 - val_loss: 3.1439e-04\n",
      "Epoch 1177/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0176 - val_loss: 3.2186e-04\n",
      "Epoch 1178/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0228 - val_loss: 6.6167e-04\n",
      "Epoch 1179/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 5.9537e-04\n",
      "Epoch 1180/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0343 - val_loss: 4.8659e-04\n",
      "Epoch 1181/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0369 - val_loss: 6.2156e-04\n",
      "Epoch 1182/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0505 - val_loss: 5.8439e-04\n",
      "Epoch 1183/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0299 - val_loss: 9.3932e-04\n",
      "Epoch 1184/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0487 - val_loss: 3.6091e-04\n",
      "Epoch 1185/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0786 - val_loss: 0.0012\n",
      "Epoch 1186/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0560 - val_loss: 7.2636e-04\n",
      "Epoch 1187/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0286 - val_loss: 5.5825e-04\n",
      "Epoch 1188/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0206 - val_loss: 6.4811e-04\n",
      "Epoch 1189/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0281 - val_loss: 3.2316e-04\n",
      "Epoch 1190/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0379 - val_loss: 2.9035e-04\n",
      "Epoch 1191/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0243 - val_loss: 3.0748e-04\n",
      "Epoch 1192/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0969 - val_loss: 5.9094e-04\n",
      "Epoch 1193/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0842 - val_loss: 4.1279e-04\n",
      "Epoch 1194/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0853 - val_loss: 6.8832e-04\n",
      "Epoch 1195/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0320 - val_loss: 6.5284e-04\n",
      "Epoch 1196/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1074 - val_loss: 5.7841e-04\n",
      "Epoch 1197/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0602 - val_loss: 3.3480e-04\n",
      "Epoch 1198/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0620 - val_loss: 5.4260e-04\n",
      "Epoch 1199/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1237 - val_loss: 5.3209e-04\n",
      "Epoch 1200/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1634 - val_loss: 4.4940e-04\n",
      "Epoch 1201/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0514 - val_loss: 4.4373e-04\n",
      "Epoch 1202/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1520 - val_loss: 5.7871e-04\n",
      "Epoch 1203/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1087 - val_loss: 4.1346e-04\n",
      "Epoch 1204/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1773 - val_loss: 4.0497e-04\n",
      "Epoch 1205/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1077 - val_loss: 8.6868e-04\n",
      "Epoch 1206/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3306 - val_loss: 8.2947e-04\n",
      "Epoch 1207/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0646 - val_loss: 6.0447e-04\n",
      "Epoch 1208/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0330 - val_loss: 3.1916e-04\n",
      "Epoch 1209/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0504 - val_loss: 3.2906e-04\n",
      "Epoch 1210/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0539 - val_loss: 7.1881e-04\n",
      "Epoch 1211/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0579 - val_loss: 3.1348e-04\n",
      "Epoch 1212/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0494 - val_loss: 3.1047e-04\n",
      "Epoch 1213/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0327 - val_loss: 3.3652e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1214/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0216 - val_loss: 3.8248e-04\n",
      "Epoch 1215/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0234 - val_loss: 3.3805e-04\n",
      "Epoch 1216/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0665 - val_loss: 5.0479e-04\n",
      "Epoch 1217/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0542 - val_loss: 6.0137e-04\n",
      "Epoch 1218/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0245 - val_loss: 3.3976e-04\n",
      "Epoch 1219/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0210 - val_loss: 3.2081e-04\n",
      "Epoch 1220/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0247 - val_loss: 4.0631e-04\n",
      "Epoch 1221/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0175 - val_loss: 3.9685e-04\n",
      "Epoch 1222/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0220 - val_loss: 3.9359e-04\n",
      "Epoch 1223/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0185 - val_loss: 3.6657e-04\n",
      "Epoch 1224/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0399 - val_loss: 3.7801e-04\n",
      "Epoch 1225/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0422 - val_loss: 3.1131e-04\n",
      "Epoch 1226/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 2.9176e-04\n",
      "Epoch 1227/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 2.8270e-04\n",
      "Epoch 1228/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0195 - val_loss: 2.6892e-04\n",
      "Epoch 1229/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0174 - val_loss: 3.0974e-04\n",
      "Epoch 1230/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0321 - val_loss: 3.8858e-04\n",
      "Epoch 1231/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0452 - val_loss: 6.0821e-04\n",
      "Epoch 1232/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0323 - val_loss: 3.3928e-04\n",
      "Epoch 1233/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0473 - val_loss: 5.2694e-04\n",
      "Epoch 1234/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0831 - val_loss: 0.0020\n",
      "Epoch 1235/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1145 - val_loss: 5.5770e-04\n",
      "Epoch 1236/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2386 - val_loss: 0.0014\n",
      "Epoch 1237/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0593 - val_loss: 5.0357e-04\n",
      "Epoch 1238/1500\n",
      "2000/2000 [==============================] - 0s 11us/step - loss: 0.0306 - val_loss: 6.9245e-04\n",
      "Epoch 1239/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0384 - val_loss: 4.9544e-04\n",
      "Epoch 1240/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0202 - val_loss: 3.6265e-04\n",
      "Epoch 1241/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0678 - val_loss: 3.7478e-04\n",
      "Epoch 1242/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0753 - val_loss: 5.5963e-04\n",
      "Epoch 1243/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0490 - val_loss: 3.1254e-04\n",
      "Epoch 1244/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0998 - val_loss: 3.6298e-04\n",
      "Epoch 1245/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0503 - val_loss: 5.6475e-04\n",
      "Epoch 1246/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0280 - val_loss: 4.0603e-04\n",
      "Epoch 1247/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0202 - val_loss: 2.9860e-04\n",
      "Epoch 1248/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0234 - val_loss: 3.2103e-04\n",
      "Epoch 1249/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0187 - val_loss: 3.1438e-04\n",
      "Epoch 1250/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0280 - val_loss: 2.9185e-04\n",
      "Epoch 1251/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0322 - val_loss: 3.5747e-04\n",
      "Epoch 1252/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0696 - val_loss: 9.2543e-04\n",
      "Epoch 1253/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0885 - val_loss: 7.6985e-04\n",
      "Epoch 1254/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0604 - val_loss: 4.4510e-04\n",
      "Epoch 1255/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0291 - val_loss: 3.3596e-04\n",
      "Epoch 1256/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0234 - val_loss: 2.7939e-04\n",
      "Epoch 1257/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0381 - val_loss: 2.9528e-04\n",
      "Epoch 1258/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0478 - val_loss: 6.6279e-04\n",
      "Epoch 1259/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1656 - val_loss: 0.0023\n",
      "Epoch 1260/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.3040 - val_loss: 9.0431e-04\n",
      "Epoch 1261/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1907 - val_loss: 5.7275e-04\n",
      "Epoch 1262/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1552 - val_loss: 7.8025e-04\n",
      "Epoch 1263/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0731 - val_loss: 5.8059e-04\n",
      "Epoch 1264/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0778 - val_loss: 3.4312e-04\n",
      "Epoch 1265/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0491 - val_loss: 7.3988e-04\n",
      "Epoch 1266/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0412 - val_loss: 4.3331e-04\n",
      "Epoch 1267/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0288 - val_loss: 2.9780e-04\n",
      "Epoch 1268/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0179 - val_loss: 3.7093e-04\n",
      "Epoch 1269/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0679 - val_loss: 0.0011\n",
      "Epoch 1270/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0620 - val_loss: 4.4030e-04\n",
      "Epoch 1271/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1091 - val_loss: 7.8053e-04\n",
      "Epoch 1272/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0670 - val_loss: 3.1621e-04\n",
      "Epoch 1273/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1223 - val_loss: 4.2601e-04\n",
      "Epoch 1274/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0911 - val_loss: 6.1572e-04\n",
      "Epoch 1275/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0643 - val_loss: 3.3564e-04\n",
      "Epoch 1276/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0205 - val_loss: 6.3068e-04\n",
      "Epoch 1277/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0225 - val_loss: 3.2096e-04\n",
      "Epoch 1278/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0282 - val_loss: 3.6660e-04\n",
      "Epoch 1279/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0196 - val_loss: 3.1519e-04\n",
      "Epoch 1280/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0191 - val_loss: 3.9938e-04\n",
      "Epoch 1281/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0195 - val_loss: 6.6132e-04\n",
      "Epoch 1282/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0349 - val_loss: 6.3264e-04\n",
      "Epoch 1283/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0419 - val_loss: 4.1587e-04\n",
      "Epoch 1284/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0257 - val_loss: 4.1306e-04\n",
      "Epoch 1285/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 3.2124e-04\n",
      "Epoch 1286/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0348 - val_loss: 4.1226e-04\n",
      "Epoch 1287/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0556 - val_loss: 3.5177e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1288/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0229 - val_loss: 7.5684e-04\n",
      "Epoch 1289/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0398 - val_loss: 3.8889e-04\n",
      "Epoch 1290/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0295 - val_loss: 3.4966e-04\n",
      "Epoch 1291/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0415 - val_loss: 5.0389e-04\n",
      "Epoch 1292/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0247 - val_loss: 6.9626e-04\n",
      "Epoch 1293/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0718 - val_loss: 5.3051e-04\n",
      "Epoch 1294/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.3921 - val_loss: 5.9596e-04\n",
      "Epoch 1295/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1946 - val_loss: 5.4619e-04\n",
      "Epoch 1296/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0743 - val_loss: 5.4015e-04\n",
      "Epoch 1297/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0563 - val_loss: 0.0010\n",
      "Epoch 1298/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0219 - val_loss: 5.4147e-04\n",
      "Epoch 1299/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0191 - val_loss: 4.3806e-04\n",
      "Epoch 1300/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0230 - val_loss: 5.1041e-04\n",
      "Epoch 1301/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0320 - val_loss: 4.6622e-04\n",
      "Epoch 1302/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0231 - val_loss: 3.3342e-04\n",
      "Epoch 1303/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0364 - val_loss: 3.0519e-04\n",
      "Epoch 1304/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0340 - val_loss: 4.5694e-04\n",
      "Epoch 1305/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0426 - val_loss: 4.5684e-04\n",
      "Epoch 1306/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0303 - val_loss: 6.1396e-04\n",
      "Epoch 1307/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0513 - val_loss: 4.1008e-04\n",
      "Epoch 1308/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1036 - val_loss: 2.8474e-04\n",
      "Epoch 1309/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0834 - val_loss: 3.7970e-04\n",
      "Epoch 1310/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0471 - val_loss: 9.7562e-04\n",
      "Epoch 1311/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0546 - val_loss: 3.5728e-04\n",
      "Epoch 1312/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0224 - val_loss: 2.7481e-04\n",
      "Epoch 1313/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0256 - val_loss: 3.7118e-04\n",
      "Epoch 1314/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0312 - val_loss: 3.5756e-04\n",
      "Epoch 1315/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0710 - val_loss: 4.5018e-04\n",
      "Epoch 1316/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0440 - val_loss: 0.0010\n",
      "Epoch 1317/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0415 - val_loss: 4.6156e-04\n",
      "Epoch 1318/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0414 - val_loss: 3.2722e-04\n",
      "Epoch 1319/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0315 - val_loss: 3.3748e-04\n",
      "Epoch 1320/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0853 - val_loss: 6.5257e-04\n",
      "Epoch 1321/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0536 - val_loss: 5.7636e-04\n",
      "Epoch 1322/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0291 - val_loss: 2.4551e-04\n",
      "Epoch 1323/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0300 - val_loss: 3.0012e-04\n",
      "Epoch 1324/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0251 - val_loss: 4.2935e-04\n",
      "Epoch 1325/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 3.0466e-04\n",
      "Epoch 1326/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 3.4962e-04\n",
      "Epoch 1327/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0261 - val_loss: 5.6141e-04\n",
      "Epoch 1328/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0213 - val_loss: 3.3248e-04\n",
      "Epoch 1329/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0513 - val_loss: 4.7510e-04\n",
      "Epoch 1330/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0637 - val_loss: 3.3387e-04\n",
      "Epoch 1331/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1868 - val_loss: 5.0037e-04\n",
      "Epoch 1332/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0632 - val_loss: 3.1903e-04\n",
      "Epoch 1333/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0800 - val_loss: 4.9247e-04\n",
      "Epoch 1334/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0515 - val_loss: 4.6362e-04\n",
      "Epoch 1335/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0283 - val_loss: 2.3803e-04\n",
      "Epoch 1336/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0233 - val_loss: 2.1595e-04\n",
      "Epoch 1337/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0238 - val_loss: 2.3824e-04\n",
      "Epoch 1338/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0311 - val_loss: 2.2522e-04\n",
      "Epoch 1339/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0347 - val_loss: 6.9747e-04\n",
      "Epoch 1340/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0524 - val_loss: 4.4507e-04\n",
      "Epoch 1341/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0184 - val_loss: 2.3312e-04\n",
      "Epoch 1342/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0323 - val_loss: 3.9359e-04\n",
      "Epoch 1343/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0242 - val_loss: 2.3614e-04\n",
      "Epoch 1344/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0383 - val_loss: 2.8805e-04\n",
      "Epoch 1345/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1045 - val_loss: 2.8531e-04\n",
      "Epoch 1346/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1358 - val_loss: 2.0643e-04\n",
      "Epoch 1347/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1144 - val_loss: 4.2326e-04\n",
      "Epoch 1348/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1817 - val_loss: 9.0820e-04\n",
      "Epoch 1349/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1952 - val_loss: 2.5281e-04\n",
      "Epoch 1350/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1392 - val_loss: 0.0017\n",
      "Epoch 1351/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0939 - val_loss: 3.4811e-04\n",
      "Epoch 1352/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0204 - val_loss: 2.2471e-04\n",
      "Epoch 1353/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0207 - val_loss: 2.0504e-04\n",
      "Epoch 1354/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0297 - val_loss: 3.2742e-04\n",
      "Epoch 1355/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1360 - val_loss: 6.3216e-04\n",
      "Epoch 1356/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0907 - val_loss: 4.6482e-04\n",
      "Epoch 1357/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0848 - val_loss: 4.9853e-04\n",
      "Epoch 1358/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0653 - val_loss: 6.9918e-04\n",
      "Epoch 1359/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0322 - val_loss: 3.9557e-04\n",
      "Epoch 1360/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0835 - val_loss: 6.4341e-04\n",
      "Epoch 1361/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1151 - val_loss: 4.1080e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1362/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0359 - val_loss: 2.5469e-04\n",
      "Epoch 1363/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0355 - val_loss: 4.9169e-04\n",
      "Epoch 1364/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0537 - val_loss: 1.6941e-04\n",
      "Epoch 1365/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0249 - val_loss: 1.9304e-04\n",
      "Epoch 1366/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0905 - val_loss: 2.7645e-04\n",
      "Epoch 1367/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0903 - val_loss: 5.1038e-04\n",
      "Epoch 1368/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0674 - val_loss: 0.0010\n",
      "Epoch 1369/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0675 - val_loss: 1.8173e-04\n",
      "Epoch 1370/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0464 - val_loss: 9.1436e-04\n",
      "Epoch 1371/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0219 - val_loss: 2.5955e-04\n",
      "Epoch 1372/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0553 - val_loss: 9.6049e-04\n",
      "Epoch 1373/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0807 - val_loss: 3.0013e-04\n",
      "Epoch 1374/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0423 - val_loss: 3.9651e-04\n",
      "Epoch 1375/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0600 - val_loss: 3.7342e-04\n",
      "Epoch 1376/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0388 - val_loss: 7.1196e-04\n",
      "Epoch 1377/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0434 - val_loss: 2.1698e-04\n",
      "Epoch 1378/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1766 - val_loss: 0.0013\n",
      "Epoch 1379/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.3135 - val_loss: 3.7227e-04\n",
      "Epoch 1380/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1504 - val_loss: 4.4639e-04\n",
      "Epoch 1381/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.1051 - val_loss: 2.0256e-04\n",
      "Epoch 1382/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0918 - val_loss: 3.0249e-04\n",
      "Epoch 1383/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1020 - val_loss: 3.0447e-04\n",
      "Epoch 1384/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0644 - val_loss: 1.8448e-04\n",
      "Epoch 1385/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0325 - val_loss: 3.4774e-04\n",
      "Epoch 1386/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0674 - val_loss: 2.1044e-04\n",
      "Epoch 1387/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0465 - val_loss: 1.9545e-04\n",
      "Epoch 1388/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0409 - val_loss: 2.1454e-04\n",
      "Epoch 1389/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0535 - val_loss: 2.7335e-04\n",
      "Epoch 1390/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0212 - val_loss: 4.8605e-04\n",
      "Epoch 1391/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0293 - val_loss: 3.5859e-04\n",
      "Epoch 1392/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0190 - val_loss: 1.6831e-04\n",
      "Epoch 1393/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 1.8976e-04\n",
      "Epoch 1394/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0171 - val_loss: 2.7364e-04\n",
      "Epoch 1395/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0314 - val_loss: 2.7151e-04\n",
      "Epoch 1396/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0335 - val_loss: 1.8548e-04\n",
      "Epoch 1397/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1142 - val_loss: 4.0755e-04\n",
      "Epoch 1398/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1322 - val_loss: 0.0014\n",
      "Epoch 1399/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0305 - val_loss: 3.2559e-04\n",
      "Epoch 1400/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0184 - val_loss: 1.7440e-04\n",
      "Epoch 1401/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0183 - val_loss: 1.7235e-04\n",
      "Epoch 1402/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0156 - val_loss: 1.6136e-04\n",
      "Epoch 1403/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0380 - val_loss: 2.4845e-04\n",
      "Epoch 1404/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0610 - val_loss: 2.1439e-04\n",
      "Epoch 1405/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0531 - val_loss: 2.1107e-04\n",
      "Epoch 1406/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0236 - val_loss: 5.2328e-04\n",
      "Epoch 1407/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0356 - val_loss: 1.9732e-04\n",
      "Epoch 1408/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0580 - val_loss: 2.3182e-04\n",
      "Epoch 1409/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0523 - val_loss: 2.4459e-04\n",
      "Epoch 1410/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0299 - val_loss: 1.6058e-04\n",
      "Epoch 1411/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0248 - val_loss: 1.7615e-04\n",
      "Epoch 1412/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0192 - val_loss: 3.1242e-04\n",
      "Epoch 1413/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0317 - val_loss: 2.4007e-04\n",
      "Epoch 1414/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0392 - val_loss: 2.8450e-04\n",
      "Epoch 1415/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0167 - val_loss: 2.0569e-04\n",
      "Epoch 1416/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0220 - val_loss: 1.7778e-04\n",
      "Epoch 1417/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0179 - val_loss: 4.2376e-04\n",
      "Epoch 1418/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0152 - val_loss: 1.6082e-04\n",
      "Epoch 1419/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0236 - val_loss: 2.4687e-04\n",
      "Epoch 1420/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0323 - val_loss: 2.3472e-04\n",
      "Epoch 1421/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0415 - val_loss: 1.7585e-04\n",
      "Epoch 1422/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0755 - val_loss: 5.7465e-04\n",
      "Epoch 1423/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1954 - val_loss: 0.0013\n",
      "Epoch 1424/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.1060 - val_loss: 8.6123e-04\n",
      "Epoch 1425/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1978 - val_loss: 3.4730e-04\n",
      "Epoch 1426/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1769 - val_loss: 3.0047e-04\n",
      "Epoch 1427/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0384 - val_loss: 4.8225e-04\n",
      "Epoch 1428/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0467 - val_loss: 3.2374e-04\n",
      "Epoch 1429/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0255 - val_loss: 1.8486e-04\n",
      "Epoch 1430/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0516 - val_loss: 5.3414e-04\n",
      "Epoch 1431/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.2678 - val_loss: 5.7326e-04\n",
      "Epoch 1432/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1765 - val_loss: 4.6514e-04\n",
      "Epoch 1433/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0315 - val_loss: 2.2366e-04\n",
      "Epoch 1434/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 3.5830e-04\n",
      "Epoch 1435/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0217 - val_loss: 1.4146e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1436/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0156 - val_loss: 1.5010e-04\n",
      "Epoch 1437/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0321 - val_loss: 5.3388e-04\n",
      "Epoch 1438/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0666 - val_loss: 4.0303e-04\n",
      "Epoch 1439/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0309 - val_loss: 2.6555e-04\n",
      "Epoch 1440/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0287 - val_loss: 1.6458e-04\n",
      "Epoch 1441/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0251 - val_loss: 2.3965e-04\n",
      "Epoch 1442/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0328 - val_loss: 2.4672e-04\n",
      "Epoch 1443/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0315 - val_loss: 3.7557e-04\n",
      "Epoch 1444/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0843 - val_loss: 6.6395e-04\n",
      "Epoch 1445/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0415 - val_loss: 2.1616e-04\n",
      "Epoch 1446/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0299 - val_loss: 1.4681e-04\n",
      "Epoch 1447/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0934 - val_loss: 3.0807e-04\n",
      "Epoch 1448/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0438 - val_loss: 2.9996e-04\n",
      "Epoch 1449/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0265 - val_loss: 1.4129e-04\n",
      "Epoch 1450/1500\n",
      "2000/2000 [==============================] - 0s 8us/step - loss: 0.0798 - val_loss: 3.8023e-04\n",
      "Epoch 1451/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0902 - val_loss: 6.0092e-04\n",
      "Epoch 1452/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0433 - val_loss: 2.7553e-04\n",
      "Epoch 1453/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0237 - val_loss: 2.0877e-04\n",
      "Epoch 1454/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0250 - val_loss: 1.5460e-04\n",
      "Epoch 1455/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0264 - val_loss: 1.4651e-04\n",
      "Epoch 1456/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0210 - val_loss: 1.4465e-04\n",
      "Epoch 1457/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0398 - val_loss: 1.6750e-04\n",
      "Epoch 1458/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0433 - val_loss: 2.2109e-04\n",
      "Epoch 1459/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0198 - val_loss: 1.4691e-04\n",
      "Epoch 1460/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0337 - val_loss: 3.1201e-04\n",
      "Epoch 1461/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0371 - val_loss: 2.9298e-04\n",
      "Epoch 1462/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0242 - val_loss: 1.5520e-04\n",
      "Epoch 1463/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0301 - val_loss: 1.4415e-04\n",
      "Epoch 1464/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0418 - val_loss: 2.7294e-04\n",
      "Epoch 1465/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0636 - val_loss: 0.0010\n",
      "Epoch 1466/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0606 - val_loss: 3.0506e-04\n",
      "Epoch 1467/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0533 - val_loss: 3.2985e-04\n",
      "Epoch 1468/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0635 - val_loss: 2.3004e-04\n",
      "Epoch 1469/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0524 - val_loss: 1.6941e-04\n",
      "Epoch 1470/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0315 - val_loss: 1.4566e-04\n",
      "Epoch 1471/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0228 - val_loss: 1.4459e-04\n",
      "Epoch 1472/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0227 - val_loss: 1.6037e-04\n",
      "Epoch 1473/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0251 - val_loss: 3.5962e-04\n",
      "Epoch 1474/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0799 - val_loss: 3.0079e-04\n",
      "Epoch 1475/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0294 - val_loss: 3.3924e-04\n",
      "Epoch 1476/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0160 - val_loss: 1.8996e-04\n",
      "Epoch 1477/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0413 - val_loss: 3.2904e-04\n",
      "Epoch 1478/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0575 - val_loss: 2.7630e-04\n",
      "Epoch 1479/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0539 - val_loss: 2.9960e-04\n",
      "Epoch 1480/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0610 - val_loss: 2.2927e-04\n",
      "Epoch 1481/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0652 - val_loss: 4.3510e-04\n",
      "Epoch 1482/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0551 - val_loss: 3.2256e-04\n",
      "Epoch 1483/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0340 - val_loss: 2.7837e-04\n",
      "Epoch 1484/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0332 - val_loss: 2.3964e-04\n",
      "Epoch 1485/1500\n",
      "2000/2000 [==============================] - 0s 10us/step - loss: 0.0504 - val_loss: 1.3155e-04\n",
      "Epoch 1486/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1343 - val_loss: 4.0767e-04\n",
      "Epoch 1487/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0780 - val_loss: 2.4527e-04\n",
      "Epoch 1488/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0342 - val_loss: 3.3736e-04\n",
      "Epoch 1489/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0261 - val_loss: 4.1982e-04\n",
      "Epoch 1490/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0266 - val_loss: 4.8817e-04\n",
      "Epoch 1491/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0378 - val_loss: 1.7841e-04\n",
      "Epoch 1492/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0401 - val_loss: 5.8901e-04\n",
      "Epoch 1493/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0846 - val_loss: 1.5474e-04\n",
      "Epoch 1494/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1191 - val_loss: 0.0011\n",
      "Epoch 1495/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1892 - val_loss: 0.0011\n",
      "Epoch 1496/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.1069 - val_loss: 3.0655e-04\n",
      "Epoch 1497/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0620 - val_loss: 1.7545e-04\n",
      "Epoch 1498/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0507 - val_loss: 1.9679e-04\n",
      "Epoch 1499/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0953 - val_loss: 4.6662e-04\n",
      "Epoch 1500/1500\n",
      "2000/2000 [==============================] - 0s 9us/step - loss: 0.0485 - val_loss: 2.8052e-04\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(X_train, Y_train, epochs=1500, batch_size=100, validation_data=(X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "\n",
    "Y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5ycdXn38c81p52ZPee0IQkxASIUQxMRoohEKwcPeIDHE2gV8NR6QKvVqvX1iLX0QaWth6d9RKwoKFBQsbXiA1qqRSqlBEggQDkFgpvjbpLd7Hl3Zq7+cd87bNZNMrvZnfvene/79cpr5j5fu0nmmt/vd9+/y9wdERERgETUAYiISHwoKYiISJmSgoiIlCkpiIhImZKCiIiUKSmIiEiZkoLMaWbmZnZc+P4qM/vflew7heu8w8x+PtU4ReJCSUFizcxuM7MvTLD+jWa208xSlZ7L3f/Y3f9yGmJaESaQ8rXd/Xp3P+dIzz3BtV5hZiUz6w3/tJvZzWZ26iTO8Xkz+/50xyZzk5KCxN21wB+amY1b/07gencvRBBTtW139wagEXgJ8N/Ar83szGjDkrlISUHi7p+A+cAZoyvMrBV4HXCdma0zs7vNrMvMdpjZ35lZZqITmdl3zezyMcufDI/ZbmbvHrfvuWb2gJntN7Pfmtnnx2y+M3ztCr+9n2ZmF5vZXWOOf6mZ3Wtm3eHrS8ds+5WZ/aWZ/YeZ9ZjZz81sweF+ER5od/fPAf8AfGnMOb8WxrnfzO4zszPC9a8G/hx4WxjrpnD9JWb2aHj9LWb2R4e7vtQGJQWJNXcfAG4G3jVm9VuB/3b3TUAR+BiwADgNOBP44OHOG35YfgI4G1gFnDVul77wmi3AucAHzOy8cNv68LXF3Rvc/e5x554H3Ap8nSCh/S1wq5nNH7Pb24FLgEVAJoxlMm4BTjaz+nD5XmAtMA+4AfiBmWXd/Tbg/wA3hbGuCfffTZBYm8I4vmJmJ08yBpmDlBRkNrgWeLOZZcPld4XrcPf73P0/3b3g7s8A3wReXsE53wp8x903u3sf8PmxG939V+7+kLuX3P1B4MYKzwtBEnnC3b8XxnUjQZfP68fs8x13f3xM0ltb4blHbQeMIGnh7t939z3h9f4GqAOOP9jB7n6ruz8Vtj7+Hfg5Y1pjUruUFCT23P0uoBM4z8yOBdYRfBvGzJ5vZj8NB533E3wrPmxXDLAE+O2Y5a1jN5rZi83sl2bWYWbdwB9XeN7Rc28dt24rsHTM8s4x7/uBhgrPPWop4EBXGO8nwu6gbjPrApoPFa+ZvcbM/tPM9ob7v/ZQ+0vtUFKQ2eI6ghbCHwK3u/uucP03CL6Fr3L3JoL+8/GD0hPZARw9Znn5uO03AD8Bjnb3ZuCqMec93NTC24HnjVu3HNhWQVyVOh+43937wvGDPyNo/bS6ewvQfbB4zawO+BHw10BbuP/PqOz3JnOckoLMFtcR9Pu/j7DrKNQI7Ad6zewE4AMVnu9m4GIzO9HM8sBl47Y3AnvdfdDM1hGMAYzqAErAMQc598+A55vZ280sZWZvA04EflphbBOywFIzuwx4L0ECHI21EMaVMrPPEYwVjNoFrDCz0f/vGYLupQ6gYGavAab9dlqZnZQUZFYIxwt+A9QTfIMf9QmCD+we4FvATRWe7/8DXwX+DXgyfB3rg8AXzKwH+BxBEhk9th/4K+A/wrueXjLu3HsIBnH/FNhD8C3+de7eWUlsE1hiZr1AL8GA8knAK9x99GG524HbgMcJuqkGObBr7Afh6x4zu9/de4CPhD/TPoLf39jfqdQwU5EdEREZpZaCiIiUKSmIiEiZkoKIiJQpKYiISFnFM0zG0YIFC3zFihVRhyHj7O0bZlvXACcsbiKd1K3vInFz3333dbr7wom2zeqksGLFCjZs2BB1GDLOP2/cxkf/cSPXfeh01hzdEnU4IjKOmY1/4r5M3Ucy7U5dMQ+ADVv3RRyJiEyWkoJMu6OaszRmUzy7py/qUERkkpQUZNqZGfPrM+ztH4k6FBGZpFk9piDx1ZLP0NU/HHUYIhUZGRmhvb2dwcHBqEOZVtlslmXLlpFOpys+RklBZsSixjq2dKr7SGaH9vZ2GhsbWbFiBb9b+XV2cnf27NlDe3s7K1eurPi4Ges+MrNrzGy3mW0es26emf3CzJ4IX1vD9WZmXzezJ83sQVWAmv2OWdjAM519aG4tmQ0GBweZP3/+nEkIEHbjzp8/6dbPTI4pfBd49bh1nwbucPdVwB3hMsBrCEoirgLeTzBHvsxiLfk0hZIzMFKMOhSRisylhDBqKj/TjCUFd78T2Dtu9Rt5bi78a4Hzxqy/LiwN+J9Ai5kdNVOxycxrzAY9kz2DhYgjEZHJqPbdR23uviN8vxNoC98v5cD539s5sHRhmZm938w2mNmGjo6OmYtUjkhD3WhS0B1IIofT0DDZaqwzJ7JbUj3obJ50h7O7X+3up7j7KQsXTviUtsTAosYsALv2D0UciYhMRrWTwq7RbqHwdXe4fhsH1stdxvTWs5UqW9aaA2DbvoGIIxGZPdydT37yk6xevZqTTjqJm24KCgnu2LGD9evXs3btWlavXs2vf/1risUiF198cXnfr3zlK9MSQ7VvSf0JcBHwxfD1n8es/7CZ/SPwYqB7TDeTzEKLm7MkDNr39Ucdisik/MW/PMwj2/dP6zlPXNLEZa9/wWH3u+WWW9i4cSObNm2is7OTU089lfXr13PDDTfwqle9is9+9rMUi0X6+/vZuHEj27ZtY/Pm4AbPrq6uaYl1xpKCmd0IvAJYYGbtBIXRvwjcbGbvIagl+9Zw958BryWoldsPXDJTcUl1pJMJFjdlae9SS0GkUnfddRcXXnghyWSStrY2Xv7yl3Pvvfdy6qmn8u53v5uRkRHOO+881q5dyzHHHMOWLVu49NJLOffccznnnHOmJYYZSwrufuFBNp05wb4OfGimYpFoLG3N0a7uI5llKvlGX23r16/nzjvv5NZbb+Xiiy/m4x//OO9617vYtGkTt99+O1dddRU333wz11xzzRFfS3MfyYxZ0pJjR7eSgkilzjjjDG666SaKxSIdHR3ceeedrFu3jq1bt9LW1sb73vc+3vve93L//ffT2dlJqVTiTW96E5dffjn333//tMSgaS5kxixuzrKre4hSyUkk5t6DQSLT7fzzz+fuu+9mzZo1mBlf/vKXWbx4Mddeey1XXnkl6XSahoYGrrvuOrZt28Yll1xCqVQC4IorrpiWGJQUZMYsac4xXCyxp2+YhY11UYcjElu9vb1A8ATylVdeyZVXXnnA9osuuoiLLrrod46brtbBWOo+khmzuDl4VmFn99yaeVJkLlNSkBlzVJgUNK4gMnsoKciMOao5eIBth1oKMgvMxRl9p/IzKSnIjJlfnyGdNLarpSAxl81m2bNnz5xKDKP1FLLZ7KSO00CzzJhEwjh2YQMbn52eJy1FZsqyZctob29nrk2yOVp5bTKUFGRGPb+tkU3tSgoSb+l0elLVyeYydR/JjGrOpeke0PTZIrOFkoLMqOZcmv0DIxRLc6evVmQuiyQpmNlHzWyzmT1sZn8SrpuwfrPMbsvn5yk5PLtXs6WKzAZVTwpmthp4H7AOWAO8zsyO4+D1m2UWO76tEYDHdvZEHImIVCKKlsLvAfe4e7+7F4B/B/4XB6/fLLPYqrYGzJQURGaLKJLCZuAMM5tvZnmCOgpHc/D6zQdQjebZJZ9Jsaw1x5MdvVGHIiIVqHpScPdHgS8BPwduAzYCxXH7HLR+s2o0zz5Ht+ZVgU1klohkoNndv+3uL3L39cA+4HEOXr9ZZrkgKeipZpHZIKq7jxaFr8sJxhNu4Ln6zXBg/WaZ5Za15ujoGWJwpHj4nUUkUlE90fwjM5sPjAAfcvcuMztY/WaZ5drC2VJ37x9i+fx8xNGIyKFEkhTc/YwJ1u1hgvrNMvstaw1mS32yo0dJQSTm9ESzzLgXHt2KGTzY3h11KCJyGEoKMuNymSRLW3Js6eiLOhQROQwlBamKlQvqebpTSUEk7pQUpCqOXdjA0519c6qIichcpKQgVbFyQT29QwU6eoaiDkVEDkFJQarimIX1AGxRF5JIrCkpSFWsXBAmBQ02i8SakoJUxZLmHHWpBE93amI8kThTUpCqSCSMlQvqeXSHptAWiTMlBamapS057nqyU3MgicSYkoJUzcnPCyqsdvWPRByJiBxMVLOkfiysz7zZzG40s6yZrTSze8zsSTO7ycwyUcQmM2f5vGDeo55BJQWRuIqiRvNS4CPAKe6+GkgCFxAU3vmKux9HUGPhPdWOTWZWQzaYf3G/koJIbEXVfZQCcmaWAvLADuCVwA/D7arRPAcdt7ABgA3P7Is4EhE5mCjKcW4D/hp4liAZdAP3AV3uXgh3aweWTnS8ajTPXkfPy3P0vJxmSxWJsSi6j1qBNwIrgSVAPfDqSo9XjebZbfWSZjZvV1IQiasouo/OAp529w53HwFuAU4HWsLuJIBlwLYIYpMZtnppM1v39NM9oHEFkTiKIik8C7zEzPJmZgTV1h4Bfgm8OdxHNZrnqNVLmwF4WK0FkViKYkzhHoIB5fuBh8IYrgY+BXzczJ4E5gPfrnZsMvNWL2kC4OFt+yOOREQmElWN5suAy8at3gKsiyAcqaL5DXUsac7y0Da1FETiSE80S9W9YKkGm0XiSklBqu6kpc083dlH71Dh8DuLSFUpKUjVrV7ahDs8sl3jCiJxo6QgVbd6SXAH0maNK4jEjpKCVN2ipiyLGus0riASQ0oKEomj5+XZtX8w6jBEZBwlBYlESy6tugoiMaSkIJFozqU11YVIDCkpSCSacmm61VIQiR0lBYlESz5Nz1CBQrEUdSgiMkYUU2cfb2Ybx/zZb2Z/YmbzzOwXZvZE+Npa7dikeppzaQD2D+oBNpE4iWJCvMfcfa27rwVeBPQDPwY+Ddzh7quAO8JlmaNGk4LGFUTiJeruozOBp9x9K0HhnWvD9SrHOce15IOk0NU/HHEkIjJW1EnhAuDG8H2bu+8I3+8E2qIJSapBLQWReIosKZhZBngD8IPx29zdAT/IcarRPAc05zKAkoJI3ETZUngNcL+77wqXd5nZUQDh6+6JDlKN5rlBLQWReIoyKVzIc11HAD8hKMMJKsc555WTgp5VEImVSJKCmdUDZwO3jFn9ReBsM3sCOCtcljkqk0qQThp9w8WoQxGRMaIqx9lHUId57Lo9BHcjSY3IppIMjigpiMRJ1HcfSQ2rSycZKigpiMSJkoJEJptOMDiiaS5E4kRJQSKTS6v7SCRulBQkMlklBZHYUVKQyKj7SCR+lBQkMtl0kkENNIvEipKCRKYulWRAzymIxIqSgkQmm04wVFD3kUicKClIZDTQLBI/SgoSmWCgWUlBJE6UFCQywTQX6j4SiZOoJsRrMbMfmtl/m9mjZnaaajTXnlwmuPsoKJ8hInEQVUvha8Bt7n4CsAZ4FNVorjnZdBJ3GC6qtSASF1VPCmbWDKwHvg3g7sPu3oVqNNeculTwz09dSCLxEUVLYSXQAXzHzB4ws38I6ytUVKNZ5Tjnjmw6CcCQBptFYiOKpJACTga+4e4vBPoY11V0qBrNKsc5d4wmBbUUROIjiqTQDrS7+z3h8g8JkkRFNZpl7simg39+A2opiMTGpJOCmdWbWXKqF3T3ncBvzez4cNWZwCOoRnPNyaZGWwpKCiJxcdhynGaWAC4A3gGcCgwBdWbWCdwKfNPdn5zkdS8FrjezDLAFuIQgQd1sZu8BtgJvneQ5ZZZ5rvtISUEkLiqp0fxL4F+BzwCb3b0EYGbzgD8AvmRmP3b371d6UXffCJwywSbVaK4ho91Hg5r/SCQ2KkkKZ7n7yPiV7r4X+BHwIzNLT3tkMueppSASP4dNCuMTgpllgT8EcsAN7r5noqQhcjhKCiLxM5W7j74GDAP7gH+a3nCklox2Hw3pllSR2DhsUjCzG83s2DGr5gE/IOg60vxEMmXlloKqr4nERiVjCp8FLjezHcBfAn8N/BjIAp+fudBkrlP3kUj8VDKmsAV4u5m9DLiJ4DbUc91d/5PliGQ195FI7FTSfdRqZh8CTgTeQjCWcLuZvX6mg5O5LZVMkE6anmgWiZFKBpr/CegimIvoe+7+PeD1wAvN7F9mMjiZ+3LpJAPDSgoicVHJmMJ8gvmJcsAfAbj7APCF0bmKRKYqn0nRP1yIOgwRCVWSFC4DbgOK/O5spjsmPEKkQvm6JH1qKYjERiUDzT8iuP1UZNrlM+o+EomTSgaav2Vmqw+yrd7M3m1m75jMRc3sGTN7yMw2mtmGcJ1qNNegfDpF35C6j0TiopLuo78HPmdmJwGbCaqmZYFVQBNwDXD9FK79B+7eOWZ5tEbzF83s0+Hyp6ZwXplF8nVJ9vYNRx2GiIQq6T7aCLzVzBoIZjY9ChgAHnX3x6YxljcCrwjfXwv8CiWFOS+fSdK+T91HInFRSUsBAHfvNbN7gOXTkAwc+LmZOUE9hquZRI1m4P0Ay5cvP8IwJGq5dIp+dR+JxEbFE+KZ2RuAjQR3ImFma83sJ1O87svc/WTgNcCHzGz92I2q0Vw76uuS9OvhNZHYmMwsqZcB6wgeZBvtVlo5lYu6+7bwdTfBPErrUI3mmpTLJOnX3UcisTGZpDDi7t3j1k34bf5QwjuWGkffA+cQDGCrRnMNyqdTDBdKFIqa/0gkDioeUwAeNrO3A0kzWwV8BPjNFK7ZBvzYzEavf4O732Zm96IazTWnvi6YKbV/pEhTcirlPURkOk0mKVxKMI32EHADcDvBVNqTEs66umaC9XtQjeaak8sESWFguEhTVlVdRaI2maRwrrt/liAxAGBmbyEouCMyJfkwKegBNpF4mEx7/TMVrhOpWD4TfC/RYLNIPBy2pWBmrwFeCyw1s6+P2dQE6OudHJHRloKSgkg8VNJ9tB3YALwBuG/M+h7gYzMRlNSO55KCvl+IxEEl01xsAjaZ2Q3uPlKFmKSGjHYfaaZUkXiYzEDzCjO7gqAsZ3Z0pbsfM+1RSc0oDzQrKYjEwmQGmr8DfINgHOEPgOuA789EUFI7nrslVd1HInEwmaSQc/c7AHP3re7+eeDcmQlLakW97j4SiZXJdB8NmVkCeMLMPgxsAxpmJiypFbm0uo9E4mQyLYWPAnmC6S1eBLwTeNdMBCW1I5Ewcumkuo9EYmIy9RTuDd/2ApeYWRK4ALhnJgKT2pHXTKkisVFJjeYmM/uMmf2dmZ1jgQ8DT3IEk9aZWdLMHjCzn4bLK83sHjN70sxuMrPMVM8ts4umzxaJj0q6j74HHA88BLwX+CXwFuB8d3/jEVz7o8CjY5a/BHzF3Y8D9gHvOYJzyyxSn0np4TWRmKgkKRzj7he7+zeBCwmeU3hVWGRnSsxsGcGdS/8QLhvwSuCH4S7XAudN9fwyu6ilIBIflSSF8lPM7l4E2t198Aiv+1Xgz4DRyirzgS53H/262A4snehAM3u/mW0wsw0dHR1HGIbEgcYUROKjkqSwxsz2h396gN8ffW9m+yd7QTN7HbDb3e877M4TUI3muSefSSkpiMREJXMfJaf5mqcDbzCz1xJMl9EEfA1oMbNU2FpYRvAchNSAoKWgMQWROKh6/UN3/4y7L3P3FQS3tP6bu7+DYAD7zeFuqtFcQ9R9JBIfcSqK+yng42b2JMEYw7cjjkeqJJ9JaZZUkZiYzDQX087dfwX8Kny/BVgXZTwSjXwmSd9wAXcnuBFNRKISp5aC1KhcJok7DBVKh99ZRGaUkoJErl4lOUViQ0lBIjdafa1vSHcgiURNSUEiVy60M6KWgkjUlBQkcvV16j4SiQslBYlcLh1WX1P3kUjklBQkcmopiMSHkoJELp8ZLcmploJI1JQUJHK58O4jPdUsEj0lBYmcnlMQiY+qJwUzy5rZf5nZJjN72Mz+Ilyvcpw1KldOCuo+EolaFC2FIeCV7r4GWAu82sxegspx1qxMMkEyYWopiMRAFFNnu7v3hovp8I+jcpw1y8xoqEvRM6iWgkjUIhlTMLOkmW0EdgO/AJ6iwnKcMje15NN0DYwcfkcRmVGRJAV3L7r7WoIKa+uAEyo9VjWa56aWfIau/uGowxCpeZHefeTuXQQV104jLMcZbjpoOU7VaJ6bWvNpuvrVUhCJWhR3Hy00s5bwfQ44G3gUleOsaS25NPvUUhCJXBSV144CrjWzJEFSutndf2pmjwD/aGaXAw+gcpw1pSWfoVstBZHIVT0puPuDwAsnWK9ynDWsNZ+hZ6jASLFEOqlnKkWiov99Egst+TQA3boDSSRSSgoSC6NJQXcgiURLSUFioTUfzGqyT+MKIpFSUpBYeK6loKQgEiUlBYmF51oK6j4SiZKSgsRC8+hAs1oKIpFSUpBYaKxLkUqYWgoiEVNSkFgwM1ryaQ00i0RMSUFiozmXpntALQWRKCkpSGy05jPs61NLQSRKSgoSGwsa6ujsHYo6DJGaFsUsqUeb2S/N7JGwRvNHw/XzzOwXZvZE+Npa7dgkWoua6ti1fzDqMERqWhQthQLwp+5+IvAS4ENmdiLwaeAOd18F3BEuSw1pa8qyf7DAgGo1i0QmihrNO9z9/vB9D0EthaXAGwlqM4NqNNekRY11AOzuUWtBJCqRjimY2QqCabTvAdrcfUe4aSfQdpBjVI5zjmprygKwu0fjCiJRiSwpmFkD8CPgT9x9/9ht7u6AT3ScynHOXaNJQeMKItGJJCmYWZogIVzv7reEq3eZ2VHh9qOA3VHEJtEZ7T7atV8tBZGoRHH3kRGU2nzU3f92zKafENRmBtVorkkt+TSZZILdaimIRCaKGs2nA+8EHjKzjeG6Pwe+CNxsZu8BtgJvjSA2iZCZsaipTmMKIhGKokbzXYAdZPOZ1YxF4qetKasxBZEI6YlmiZVFjXqATSRKSgoSK21NWXZroFkkMkoKEiuLmuroGSrQP1yIOhSRmqSkILHS1hg+wKbWgkgklBQkVvQAm0i0lBQkVhY1hQ+w6bZUkUgoKUisPNd9pJaCSBSUFCRWmnIp6lIJdR+JRERJQWLFzFjWmmPrnv6oQxGpSUoKEjvHL27k8V09UYchUpOUFCR2nt/WyNa9/arAJhKBqKbOvsbMdpvZ5jHrVKNZgCApuMNTHb1RhyJSc6JqKXwXePW4darRLECQFAAe26kuJJFqiyQpuPudwN5xq1WjWQBYMT9PJpnQuIJIBOI0pqAazQJAKpng2EUNSgoiEYhTUihTjWZ5flsDj+/SmIJItcUpKahGs5SdtLSZbV0Dai2IVFmckoJqNEvZm05eRjpp/PC+9qhDEakpUd2SeiNwN3C8mbWHdZm/CJxtZk8AZ4XLUqNa6zOcftwCbrznWXZ0D0QdjkjNiOruowvd/Sh3T7v7Mnf/trvvcfcz3X2Vu5/l7uPvTpIa84lzjqdnqMBbrrqbYJhJRGZanLqPRA6wemkzZ5/YRvu+Ab76r08oMYhUgZKCxNrfv/1kXr9mCV+74wkuvfEBugdGog5JZE5TUpBYy6QSfP2CtVz6yuP46YM7OO2KO9jwjHoWRWaKkoLEnpnxp+cczzff+SIyqQSXfOdenu7sizoskTlJSUFmjVe9YDE/vfRlJJPGB6+/n6GCZlEVmW5KCjKrLGvN8zdvWcOjO/bz/375VNThiMw5Sgoy65z5e2289qTFfPuup9nbNxx1OCJzipKCzEofO+v5DI4UueJnj0YdisicoqQgs9Kqtkbee8Yx/OC+du58XLPlikwXJQWZtT5y5nEcs6Ced3/3Xn7zVGfU4YjMCUoKMmvlMylu+eBLaa3P8JEbH+DB9q6oQxKZ9WKVFMzs1Wb2mJk9aWYqxymH1ZLPcOP7Xkw2neTNV93Nm7/xG259cAdPdfRSLAXTYoy+isjhWVzmkzGzJPA4cDbQDtwLXOjujxzsmFNOOcU3bNhQpQglzjp6hrj81kf4543bD1ifSycZLpZIGBy7sIGEGYua6mhrzNI7VGDz9m5OO2Y+i5qyNOfSNNalyKQS9A4VqK9LkksnSSUSfOvXW7jn6b18+U2/z+LmLPlMkrpUkvq6JP3DRXKZJAPDRRJmOE4qkSCZMFIJC16T4Wu4Ppkw9vUNs7CxDoDugRHm1WdwB8dxh4QZJXcyyQSJhAGwdU8fjdk0D2/vpjWf4QVLmjCzg/5ednYP8uzefk55XiuJhOHuDBVKZNNJAArFEj2DBQCacmlK7vQMFmioS1FyL+8HUCo5DiQTz12vf7jA/oECi5uzAGzvGmBhYx3pZIK+oQL7B0c4qjn3O3ENDBd5bFcPa49uAeDpzj5uuGcrHz/7eHKZ5O/sP16p5JhxyJ8dYEf3APPqM9SlgnO6O8/s6WdpS6789zBVpZLTP1KkoS51yJhGiiUSduC13J1iyUklD/693N0n/PkKxdIhj6uEmd3n7qdMuC1GSeE04PPu/qpw+TMA7n7FwY5RUpDxBoaL3Ld1Hw9t62Z71wC9QwU6eobY3jXA/sEROnuHaahLYUb5w3A2SFjwYTxSPPD/azJhjH7WGOU35ZehQqm8b10qQbHkFEpOXSqBWbD9YB8BZsE5cukkhZIzUixhZtSlEpTcGSl6uRWWTScoOQyH18skEwwXg/eNdSlGSiXqUslyrPv6gzmsRpNP/3CxfM3WfKb8gdg/XCCbTlIsOnVhghoqFOkZLNCaT5NJJcJEypifI3hTKDld4XWChOvsHyyUYzaDpBn1dSnSyQRDI0XMgpblaBI2OCAxBr+TYNueviFGik5LPo075Xm5WvNpkgnDLEjCXf0jpJLGvHwGM8MMuvpHKJSC5FwX/gyphDFSGv0SALu6h2jJp0mMSQy9QwV6hwosbKzjz197Aue/cNnEf3mHcaikkJrSGWfGUuC3Y5bbgReP38nM3g+8H2D58uXViUxmjVwmyctWLeBlqxZUtH+hWKJ3KPigcJ77jz1SLDE0UiKZMIaLJZqywQfH9q5BkgmjZ3CEQsnpHy6QSyfpHSpSKJYoujO/PkPJgw+lYqlEIfzwDJa9vB5gYLhU/vB1gg//0Q+OkYKTMCi6B+dw57GdPSxoyFAoOstacxTCDxFFR2cAAASYSURBVLjRz8PRD0YP12zp6MMdjlvUEKxzqEsnGRwpYsD+wQLbuwZozKZY2pojacaO7kGWz8szMFIknTQGR0qkwtZOoeQUi17+lu0EiTidDD4EN/22ixMWN5LLpOgdGuHZvQMcu7Aedw74MB4ulHh4+35OWdFK0ox0KmhZ5NLJcoJwnKRZ+XcZ/JRBUuoeGCGbTpZnzg0+Nw07MC9y2+advOh5reUWWTqZ4IFn93HSsmb29Y8wvz4T/DsoBa2zTNJIJkaTXonBkVL4swW/27G/387eYZ7p7OP04xaQMNjWNUBHzxAnLmku728GO7oGSCYS5eThHiS4UsnJpBIMFYIWZqHkpBJW/neyt2+YxU3ZA/4+08kEQ4USBixu+t0W2HSIU1KoiLtfDVwNQUsh4nBklkslE7TkM+XlBQ11h9z/efPrZzokmUZ/df5JUYcw68RpoHkbcPSY5WXhOhERqZI4JYV7gVVmttLMMsAFBHWbRUSkSmLTfeTuBTP7MHA7kASucfeHIw5LRKSmxCYpALj7z4CfRR2HiEitilP3kYiIRExJQUREypQURESkTElBRETKYjPNxVSYWQewdYqHrwQamHxiLFXpmGpeS/FV/5hqXivu8VXzWnMpvm3AVOeMf567L5xoQ6zuPpqsg/1QlTCzPiBz2B1FROKp82DzFx0JdR+JiEiZkoKIiJTN6u6jI3QLcDrQOMnjeqp0TDWvpfiqf0w1rxX3+Kp5rbkU39WTPHdFZvVAs4iITC91H4mISJmSgoiIlNXUmIKZdQNNUcchIlIlfcACdx+s9IBaaylcA+wcszxa409EZC7KAZdP5oCaG2g2szcDPwgXC9RYa0lEakJQ0Bq6gCfcfV2lB9ZaS2E8JQQRmYssfE0B2ckcWItJ4eSoAxARqZI00DyZA2oxKZwQdQAiIlWSAYqTOaAWk8K/RB2AiEgVjI4r/HgyB9XUQHM4M2o+6jhERKrkaeD33H2o0gNqKimIiMih1WL3kYiIHISSgoiIlCkpiIhImZKCiIiUKSmIiEiZkoLIIZhZ0cw2jvnz6Wk89woz2zxd5xOZDpr7R+TQBtx9bdRBiFSLWgoiU2Bmz5jZl83sITP7LzM7Lly/wsz+zcweNLM7zGx5uL7NzH5sZpvCPy8NT5U0s2+Z2cNm9nMzy0X2Q4mgpCByOLlx3UdvG7Ot291PAv4O+Gq47v8C17r77wPXA18P138d+Hd3X0MwKePD4fpVwN+7+wsIpjl+0wz/PCKHpCeaRQ7BzHrdvWGC9c8Ar3T3LWaWBna6+3wz6wSOcveRcP0Od19gZh3AsrHTDZjZCuAX7r4qXP4UkHb3SRVFEZlOaimITJ0f5P1kjJ2TpojG+SRiSgoiU/e2Ma93h+9/A1wQvn8H8Ovw/R3ABwDMLGlmk5rjXqRa9K1E5NByZrZxzPJt7j56W2qrmT1I8G3/wnDdpcB3zOyTQAdwSbj+o8DVZvYeghbBB4AdMx69yCRpTEFkCsIxhVPcvTPqWESmk7qPRESkTC0FEREpU0tBRETKlBRERKRMSUFERMqUFEREpExJQUREyv4HcB3J3ZYkAsMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the learning curves\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = range(1,len(history.history['loss'])+1)\n",
    "y = range(0,31603,10)\n",
    "ax.grid(color='white', alpha=0.25)\n",
    "plt.title(\"Validation Data\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Rate(%)\")\n",
    "plt.xticks(x)\n",
    "plt.yticks(y)\n",
    "plt.ylim(-5,105)\n",
    "ax.plot(x,100 * np.array(history.history['val_loss']), label= 'loss')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(color='white', alpha=1)\n",
    "ax.set_axisbelow(True)\n",
    "plt.title(\"Training Data\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Rate(%)\")\n",
    "plt.xticks(x)\n",
    "plt.yticks(y)\n",
    "plt.ylim(-5,105)\n",
    "ax.plot(x,100*np.array(history.history['loss']), label= 'loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting and comparing \n",
    "\n",
    "plt.title(\"Comparing with real\")\n",
    "plt.plot(X_test,Y_test, label=\"Actual\")\n",
    "plt.plot(X_test,Y_predict, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using RBF Net\n",
    "### Defining helper functions\n",
    "    - Defining the RBF Function used in the network, In this example it is the Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel(x, c, s):\n",
    "    return np.exp(-1 / (2 * np.square(s))) * np.square((x-c.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Using K means to compute cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(X, k):\n",
    "    \n",
    "    # Initializing clusters randomly from input data\n",
    "    clusters = np.random.choice(np.squeeze(X), size = k)\n",
    "    previous_clusters = clusters.copy()\n",
    "    standard_deviations = np.zeros(k)\n",
    "    converged = False\n",
    "    \n",
    "    while not converged:\n",
    "        \n",
    "        # Computing distances for each point to each clustter, and adding an extra dimension to X and clusters\n",
    "        distances = np.squeeze(np.abs(X[:, np.newaxis] - clusters[np.newaxis, :]))\n",
    " \n",
    "        # Finding the cluster that's closest to each point\n",
    "        closest_cluster = np.argmin(distances, axis = 1)\n",
    " \n",
    "        # Updating clusters by taking the mean of all of the points assigned to that cluster\n",
    "        for i in range(k):\n",
    "            points_for_each_cluster = X[closest_cluster == i]\n",
    "            if len(points_for_each_cluster) > 0:\n",
    "                clusters[i] = np.mean(points_for_each_cluster, axis=0)\n",
    " \n",
    "        # converge if clusters haven't moved more than e^-6\n",
    "        converged = np.linalg.norm(clusters - previous_clusters) < 1e-6\n",
    "        previous_clusters = clusters.copy()\n",
    " \n",
    "    distances = np.squeeze(np.abs(X[:, np.newaxis] - clusters[np.newaxis, :]))\n",
    "    closest_cluster = np.argmin(distances, axis=1)\n",
    " \n",
    "    empty_clusters = []\n",
    "    for i in range(k):\n",
    "        points_for_each_cluster = X[closest_cluster == i]\n",
    "        if len(points_for_each_cluster) < 2:\n",
    "            # keep track of clusters with no points or 1 point\n",
    "            empty_clusters.append(i)\n",
    "            continue\n",
    "        else:\n",
    "            standard_deviations[i] = np.std(X[closest_cluster == i])\n",
    " \n",
    "    # if there are clusters with 0 or 1 points, take the mean std of the other clusters\n",
    "    if len(empty_clusters) > 0:\n",
    "        average_points = []\n",
    "        for i in range(k):\n",
    "            if i not in empty_clusters:\n",
    "                average_points.append(X[closest_cluster == i])\n",
    "        average_points = np.concatenate(average_points).ravel()\n",
    "        standard_deviations[empty_clusters] = np.mean(np.std(average_points))\n",
    " \n",
    "    return clusters, standard_deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definning RBF Net Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF_NN(object):\n",
    "    \n",
    "    def __init__(self, k = 2, kernel = Kernel):\n",
    "        \n",
    "        self.k = k\n",
    "        self.kernel = kernel\n",
    " \n",
    "        self.w = np.random.randn(k,1)\n",
    "        self.b = np.random.randn(1)\n",
    "                \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # use a fixed std \n",
    "        self.centers, _ = Kmeans(X, self.k)\n",
    "        self.centers = self.centers.reshape((self.centers.shape[0],1))\n",
    "        self.stds = max([np.abs(c1 - c2) for c1 in self.centers for c2 in self.centers])\n",
    "        \n",
    "        # Computing weights using matrix inverse    \n",
    "        A = self.kernel(X, self.centers, self.stds)\n",
    "        Ai = np.linalg.pinv(A)\n",
    "        self.w = np.dot(Ai, Y_train)\n",
    "                \n",
    "    def predict(self, X):\n",
    "        Y_predict = []\n",
    "        A = self.kernel(X, self.centers, self.stds)\n",
    "        F = np.dot(A, self.w)\n",
    "        return F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training and test data\n",
    "\n",
    "X_train = np.random.uniform(low = -3, high = 3, size = (2000, 1))\n",
    "\n",
    "Y_train = np.power(X_train, 2)\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "\n",
    "X_test = np.random.uniform(low = -1500, high = 1500, size = (100, 1))\n",
    "X_test.sort(axis = 0)\n",
    "\n",
    "Y_test = np.power(X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_nn = RBF_NN(k=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = rbf_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting and comparing \n",
    "\n",
    "plt.title(\"Comparing with real\")\n",
    "plt.plot(X_test, Y_test, label=\"Actual\")\n",
    "plt.plot(X_test, Y_predict, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - It is shown that when using RBF networks and approximating functions using gaussians, we can get a lot better results because of Aprroximation theorem which states that every functions can be approximated bus using N number of Gaussians. Also I could use a Inverse-Matrix approach for computing the weights, and It was a lot faster and computationaly efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
